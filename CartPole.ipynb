{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, I'll build a neural network that can learn to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](cart-pole.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions: 2\n",
      "States: Box(4,)\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# environment details\n",
    "print('Number of possible actions:', env.action_space.n)\n",
    "print('States:', env.observation_space)\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    env.render()\n",
    "    sleep(0.15)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. The network's goal is to maximize the reward by keeping the pole vertical.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "The neural network accepts a state $s$ as input and the output will be $Q$-values for each available action $a$.\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "Below is one implementation of the $Q$-network that uses 3 fully connected layers with ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def fully_connected(name, input_tensor, num_units, activation=tf.nn.relu):\n",
    "    \"\"\"Returns a fully connected layer\"\"\"\n",
    "    # initialize weights\n",
    "    w = tf.compat.v1.get_variable(f\"W_{name}\", shape=[input_tensor.get_shape()[1], num_units],\n",
    "                                  initializer=tf.compat.v1.initializers.he_uniform(),\n",
    "                                  dtype=tf.float32, trainable=True)\n",
    "    # initialize bias\n",
    "    b = tf.compat.v1.get_variable(f\"B_{name}\", shape=[num_units], \n",
    "                                  initializer=tf.constant_initializer(0.0), \n",
    "                                  dtype=tf.float32,\n",
    "                                  trainable=True)\n",
    "    # output\n",
    "    out = tf.matmul(input_tensor, w) + b\n",
    "    # add activation\n",
    "    if activation:\n",
    "        out = activation(out, name=f\"activation_{name}\")\n",
    "    # change name\n",
    "    out = tf.compat.v1.identity(out, name=name)\n",
    "\n",
    "    return out\n",
    "    \n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        with tf.variable_scope(name):\n",
    "            # state inputs to the Q-network\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = fully_connected(\"h1\", self.inputs_, hidden_size)\n",
    "            self.fc2 = fully_connected(\"h2\", self.fc1, hidden_size)\n",
    "            self.fc3 = fully_connected(\"h3\", self.fc2, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = fully_connected(\"output\", self.fc3, action_size, activation=None)\n",
    "            \n",
    "            ### Train using mean squared error and Adam gradient descent.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "This `Memory` object will store model's experience $<state, action, reward, next state>$. \n",
    "This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. \n",
    "Then, we'll sample a random mini-batch of transitions $<state, action, reward, next state>$ and train on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 700          # max number of episodes to learn from\n",
    "max_steps = 500               # max steps in an episode\n",
    "gamma = 1.0                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0002            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000            # memory capacity\n",
    "batch_size = 32                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "I re-initialize the simulation and pre-populate the memory in order to use later on the mini-batch.\n",
    "To do this the agent will take random actions and storing the transitions in memory.\n",
    "I also decided to modify the value of the reward in order to get a bigger reward if the cart stays centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    # reduce the reward if the cart is not centered\n",
    "    reward = max(0, reward * (1 - abs(next_state[1]/2.4)))\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now it is time to train the agent.\n",
    "The training will stop automatically after 700 episodes or after 10 consecutive very high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 1.239736003157733 Explore P: 0.9996\n",
      "Episode: 2 Total reward: 28.30551052324786 Explore P: 0.9931\n",
      "Episode: 3 Total reward: 22.054987871895417 Explore P: 0.9884\n",
      "Episode: 4 Total reward: 8.016651154103966 Explore P: 0.9860\n",
      "Episode: 5 Total reward: 88.72568934323803 Explore P: 0.9654\n",
      "Episode: 6 Total reward: 51.961893859446896 Explore P: 0.9521\n",
      "Episode: 7 Total reward: 11.834252389417788 Explore P: 0.9493\n",
      "Episode: 8 Total reward: 29.010318485116336 Explore P: 0.9429\n",
      "Episode: 9 Total reward: 20.998116003472823 Explore P: 0.9386\n",
      "Episode: 10 Total reward: 14.478790465545714 Explore P: 0.9351\n",
      "Episode: 11 Total reward: 8.387561977510982 Explore P: 0.9331\n",
      "Episode: 12 Total reward: 6.059037388569927 Explore P: 0.9312\n",
      "Episode: 13 Total reward: 13.475857681509043 Explore P: 0.9283\n",
      "Episode: 14 Total reward: 15.461032855452531 Explore P: 0.9248\n",
      "Episode: 15 Total reward: 23.886581130207535 Explore P: 0.9197\n",
      "Episode: 16 Total reward: 25.57043841566786 Explore P: 0.9144\n",
      "Episode: 17 Total reward: 15.201626597012336 Explore P: 0.9114\n",
      "Episode: 18 Total reward: 28.633113295361497 Explore P: 0.9056\n",
      "Episode: 19 Total reward: 8.296415205015414 Explore P: 0.9036\n",
      "Episode: 20 Total reward: 31.432521120077396 Explore P: 0.8972\n",
      "Episode: 21 Total reward: 16.092816607307213 Explore P: 0.8935\n",
      "Episode: 22 Total reward: 6.4547819195125875 Explore P: 0.8919\n",
      "Episode: 23 Total reward: 9.025264722656036 Explore P: 0.8898\n",
      "Episode: 24 Total reward: 22.107311235181008 Explore P: 0.8854\n",
      "Episode: 25 Total reward: 12.997252977295211 Explore P: 0.8826\n",
      "Episode: 26 Total reward: 10.50045371676582 Explore P: 0.8802\n",
      "Episode: 27 Total reward: 12.6494162883717 Explore P: 0.8774\n",
      "Episode: 28 Total reward: 6.871259269318099 Explore P: 0.8755\n",
      "Episode: 29 Total reward: 8.606361773313441 Explore P: 0.8734\n",
      "Episode: 30 Total reward: 5.31289108012433 Explore P: 0.8720\n",
      "Episode: 31 Total reward: 23.622956426404574 Explore P: 0.8672\n",
      "Episode: 32 Total reward: 33.37382903350192 Explore P: 0.8577\n",
      "Episode: 33 Total reward: 11.361015477423754 Explore P: 0.8553\n",
      "Episode: 34 Total reward: 8.600117296891554 Explore P: 0.8533\n",
      "Episode: 35 Total reward: 5.165563872054066 Explore P: 0.8518\n",
      "Episode: 36 Total reward: 15.535287781828815 Explore P: 0.8482\n",
      "Episode: 37 Total reward: 11.707025087600808 Explore P: 0.8456\n",
      "Episode: 38 Total reward: 25.906980901617207 Explore P: 0.8406\n",
      "Episode: 39 Total reward: 10.719806612319964 Explore P: 0.8381\n",
      "Episode: 40 Total reward: 9.85479061339271 Explore P: 0.8358\n",
      "Episode: 41 Total reward: 7.53611200055158 Explore P: 0.8341\n",
      "Episode: 42 Total reward: 7.888829304451814 Explore P: 0.8323\n",
      "Episode: 43 Total reward: 14.869094155155853 Explore P: 0.8292\n",
      "Episode: 44 Total reward: 16.269832974218698 Explore P: 0.8262\n",
      "Episode: 45 Total reward: 28.09933837473658 Explore P: 0.8210\n",
      "Episode: 46 Total reward: 9.309545809104355 Explore P: 0.8191\n",
      "Episode: 47 Total reward: 8.75857763488382 Explore P: 0.8170\n",
      "Episode: 48 Total reward: 7.787874123777636 Explore P: 0.8152\n",
      "Episode: 49 Total reward: 20.08169132505899 Explore P: 0.8114\n",
      "Episode: 50 Total reward: 8.559205831734008 Explore P: 0.8094\n",
      "Episode: 51 Total reward: 8.894578786395599 Explore P: 0.8075\n",
      "Episode: 52 Total reward: 19.05493721479916 Explore P: 0.8039\n",
      "Episode: 53 Total reward: 23.593722258962142 Explore P: 0.7996\n",
      "Episode: 54 Total reward: 12.154021082641206 Explore P: 0.7971\n",
      "Episode: 55 Total reward: 6.326058657056143 Explore P: 0.7955\n",
      "Episode: 56 Total reward: 16.26214739134168 Explore P: 0.7924\n",
      "Episode: 57 Total reward: 18.318093696839213 Explore P: 0.7891\n",
      "Episode: 58 Total reward: 9.91542637651295 Explore P: 0.7871\n",
      "Episode: 59 Total reward: 7.207744011371032 Explore P: 0.7855\n",
      "Episode: 60 Total reward: 9.563161320586683 Explore P: 0.7835\n",
      "Episode: 61 Total reward: 5.919337551949001 Explore P: 0.7821\n",
      "Episode: 62 Total reward: 9.76756853220104 Explore P: 0.7802\n",
      "Episode: 63 Total reward: 14.615860889882033 Explore P: 0.7773\n",
      "Episode: 64 Total reward: 17.983045672700044 Explore P: 0.7743\n",
      "Episode: 65 Total reward: 10.322964280213245 Explore P: 0.7721\n",
      "Episode: 66 Total reward: 38.25555047441653 Explore P: 0.7650\n",
      "Episode: 67 Total reward: 8.990307852399184 Explore P: 0.7633\n",
      "Episode: 68 Total reward: 16.49308991687909 Explore P: 0.7605\n",
      "Episode: 69 Total reward: 20.45780512578486 Explore P: 0.7561\n",
      "Episode: 70 Total reward: 12.442474681248877 Explore P: 0.7537\n",
      "Episode: 71 Total reward: 9.35171423670937 Explore P: 0.7520\n",
      "Episode: 72 Total reward: 15.627053834751147 Explore P: 0.7492\n",
      "Episode: 73 Total reward: 6.853279170076407 Explore P: 0.7475\n",
      "Episode: 74 Total reward: 16.957309961470127 Explore P: 0.7443\n",
      "Episode: 75 Total reward: 4.7030284806721285 Explore P: 0.7430\n",
      "Episode: 76 Total reward: 8.76176090341585 Explore P: 0.7412\n",
      "Episode: 77 Total reward: 9.568257555010248 Explore P: 0.7392\n",
      "Episode: 78 Total reward: 7.3112580163995995 Explore P: 0.7376\n",
      "Episode: 79 Total reward: 18.617887722506566 Explore P: 0.7344\n",
      "Episode: 80 Total reward: 15.80703389126948 Explore P: 0.7316\n",
      "Episode: 81 Total reward: 13.857972905208742 Explore P: 0.7290\n",
      "Episode: 82 Total reward: 18.28512631239352 Explore P: 0.7259\n",
      "Episode: 83 Total reward: 11.12137369418295 Explore P: 0.7237\n",
      "Episode: 84 Total reward: 30.327796256662896 Explore P: 0.7189\n",
      "Episode: 85 Total reward: 7.561168853295006 Explore P: 0.7173\n",
      "Episode: 86 Total reward: 7.968755256767964 Explore P: 0.7158\n",
      "Episode: 87 Total reward: 17.054150221717144 Explore P: 0.7125\n",
      "Episode: 88 Total reward: 11.234338398699196 Explore P: 0.7106\n",
      "Episode: 89 Total reward: 9.700977249502648 Explore P: 0.7089\n",
      "Episode: 90 Total reward: 7.848991046923604 Explore P: 0.7075\n",
      "Episode: 91 Total reward: 5.792038697364241 Explore P: 0.7062\n",
      "Episode: 92 Total reward: 8.360778616022289 Explore P: 0.7046\n",
      "Episode: 93 Total reward: 8.118405229566537 Explore P: 0.7031\n",
      "Episode: 94 Total reward: 6.436774373598967 Explore P: 0.7018\n",
      "Episode: 95 Total reward: 10.136671921414383 Explore P: 0.6997\n",
      "Episode: 96 Total reward: 6.592098935275052 Explore P: 0.6984\n",
      "Episode: 97 Total reward: 10.894673009608217 Explore P: 0.6962\n",
      "Episode: 98 Total reward: 17.384280273733538 Explore P: 0.6931\n",
      "Episode: 99 Total reward: 5.307435972242003 Explore P: 0.6921\n",
      "Episode: 100 Total reward: 10.616000087674045 Explore P: 0.6900\n",
      "Episode: 101 Total reward: 8.279731183435999 Explore P: 0.6884\n",
      "Episode: 102 Total reward: 5.179690039464589 Explore P: 0.6872\n",
      "Episode: 103 Total reward: 19.36097650671176 Explore P: 0.6842\n",
      "Episode: 104 Total reward: 9.211004299866218 Explore P: 0.6826\n",
      "Episode: 105 Total reward: 18.257082499262506 Explore P: 0.6795\n",
      "Episode: 106 Total reward: 14.635842086392689 Explore P: 0.6769\n",
      "Episode: 107 Total reward: 6.725879965756847 Explore P: 0.6756\n",
      "Episode: 108 Total reward: 5.2495059357020635 Explore P: 0.6745\n",
      "Episode: 109 Total reward: 6.27748493975382 Explore P: 0.6732\n",
      "Episode: 110 Total reward: 7.153372007187339 Explore P: 0.6718\n",
      "Episode: 111 Total reward: 4.767341181279106 Explore P: 0.6706\n",
      "Episode: 112 Total reward: 8.233724236346347 Explore P: 0.6691\n",
      "Episode: 113 Total reward: 6.941283142308087 Explore P: 0.6678\n",
      "Episode: 114 Total reward: 6.694923826271098 Explore P: 0.6665\n",
      "Episode: 115 Total reward: 14.274040564523785 Explore P: 0.6641\n",
      "Episode: 116 Total reward: 8.553113150775253 Explore P: 0.6626\n",
      "Episode: 117 Total reward: 17.094096396772166 Explore P: 0.6600\n",
      "Episode: 118 Total reward: 8.240896438766054 Explore P: 0.6584\n",
      "Episode: 119 Total reward: 5.173562359119164 Explore P: 0.6571\n",
      "Episode: 120 Total reward: 6.818011121003996 Explore P: 0.6557\n",
      "Episode: 121 Total reward: 6.92496076534459 Explore P: 0.6544\n",
      "Episode: 122 Total reward: 24.882712109447056 Explore P: 0.6504\n",
      "Episode: 123 Total reward: 6.436693276888049 Explore P: 0.6490\n",
      "Episode: 124 Total reward: 5.74908193525389 Explore P: 0.6477\n",
      "Episode: 125 Total reward: 19.236499412195855 Explore P: 0.6448\n",
      "Episode: 126 Total reward: 17.52210527044379 Explore P: 0.6421\n",
      "Episode: 127 Total reward: 13.379544862064616 Explore P: 0.6401\n",
      "Episode: 128 Total reward: 12.966632488887631 Explore P: 0.6381\n",
      "Episode: 129 Total reward: 7.245590974351943 Explore P: 0.6367\n",
      "Episode: 130 Total reward: 14.70168863735023 Explore P: 0.6343\n",
      "Episode: 131 Total reward: 13.197954407712489 Explore P: 0.6321\n",
      "Episode: 132 Total reward: 21.810508012804192 Explore P: 0.6289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 133 Total reward: 17.435857972690354 Explore P: 0.6264\n",
      "Episode: 134 Total reward: 12.111861849189326 Explore P: 0.6244\n",
      "Episode: 135 Total reward: 17.481280493350365 Explore P: 0.6214\n",
      "Episode: 136 Total reward: 4.406199025921408 Explore P: 0.6205\n",
      "Episode: 137 Total reward: 11.138746673572319 Explore P: 0.6187\n",
      "Episode: 138 Total reward: 13.920581789563814 Explore P: 0.6165\n",
      "Episode: 139 Total reward: 10.875687553389668 Explore P: 0.6149\n",
      "Episode: 140 Total reward: 8.175904075661716 Explore P: 0.6135\n",
      "Episode: 141 Total reward: 14.484824541849395 Explore P: 0.6115\n",
      "Episode: 142 Total reward: 11.698830020995501 Explore P: 0.6097\n",
      "Episode: 143 Total reward: 7.932993169326797 Explore P: 0.6084\n",
      "Episode: 144 Total reward: 13.670080023153108 Explore P: 0.6062\n",
      "Episode: 145 Total reward: 20.81390532705276 Explore P: 0.6028\n",
      "Episode: 146 Total reward: 11.838312074938724 Explore P: 0.6012\n",
      "Episode: 147 Total reward: 22.76381458455495 Explore P: 0.5979\n",
      "Episode: 148 Total reward: 11.82082390114391 Explore P: 0.5961\n",
      "Episode: 149 Total reward: 29.44067239659932 Explore P: 0.5920\n",
      "Episode: 150 Total reward: 20.69417609296829 Explore P: 0.5893\n",
      "Episode: 151 Total reward: 34.571340100983676 Explore P: 0.5842\n",
      "Episode: 152 Total reward: 6.014831733377858 Explore P: 0.5831\n",
      "Episode: 153 Total reward: 41.58812725832617 Explore P: 0.5771\n",
      "Episode: 154 Total reward: 7.779999212474662 Explore P: 0.5757\n",
      "Episode: 155 Total reward: 12.794067094111229 Explore P: 0.5739\n",
      "Episode: 156 Total reward: 42.1769603352709 Explore P: 0.5682\n",
      "Episode: 157 Total reward: 7.301273178983102 Explore P: 0.5670\n",
      "Episode: 158 Total reward: 13.844729378532374 Explore P: 0.5651\n",
      "Episode: 159 Total reward: 7.526081321458531 Explore P: 0.5639\n",
      "Episode: 160 Total reward: 6.7606529398307265 Explore P: 0.5626\n",
      "Episode: 161 Total reward: 13.36077134126765 Explore P: 0.5608\n",
      "Episode: 162 Total reward: 8.13718500414971 Explore P: 0.5596\n",
      "Episode: 163 Total reward: 9.550698504072857 Explore P: 0.5580\n",
      "Episode: 164 Total reward: 8.88505414894829 Explore P: 0.5566\n",
      "Episode: 165 Total reward: 4.693857802050173 Explore P: 0.5556\n",
      "Episode: 166 Total reward: 14.665689093170625 Explore P: 0.5538\n",
      "Episode: 167 Total reward: 11.676820666179381 Explore P: 0.5521\n",
      "Episode: 168 Total reward: 6.929345419049592 Explore P: 0.5510\n",
      "Episode: 169 Total reward: 5.963813948387943 Explore P: 0.5502\n",
      "Episode: 170 Total reward: 9.391846411520481 Explore P: 0.5488\n",
      "Episode: 171 Total reward: 6.86347733631208 Explore P: 0.5477\n",
      "Episode: 172 Total reward: 9.20120470936004 Explore P: 0.5462\n",
      "Episode: 173 Total reward: 49.43977649005801 Explore P: 0.5394\n",
      "Episode: 174 Total reward: 11.171571623019398 Explore P: 0.5378\n",
      "Episode: 175 Total reward: 13.502767225939202 Explore P: 0.5360\n",
      "Episode: 176 Total reward: 10.515794212719332 Explore P: 0.5345\n",
      "Episode: 177 Total reward: 8.361866348632883 Explore P: 0.5333\n",
      "Episode: 178 Total reward: 6.725677064387626 Explore P: 0.5321\n",
      "Episode: 179 Total reward: 7.220316294828454 Explore P: 0.5309\n",
      "Episode: 180 Total reward: 9.644713418145415 Explore P: 0.5295\n",
      "Episode: 181 Total reward: 12.723760789218682 Explore P: 0.5278\n",
      "Episode: 182 Total reward: 10.078645792171685 Explore P: 0.5263\n",
      "Episode: 183 Total reward: 14.286148371218724 Explore P: 0.5246\n",
      "Episode: 184 Total reward: 16.06040428469781 Explore P: 0.5224\n",
      "Episode: 185 Total reward: 8.161647115382447 Explore P: 0.5212\n",
      "Episode: 186 Total reward: 7.88738559858552 Explore P: 0.5200\n",
      "Episode: 187 Total reward: 8.14506766243957 Explore P: 0.5187\n",
      "Episode: 188 Total reward: 7.099423592084942 Explore P: 0.5177\n",
      "Episode: 189 Total reward: 28.074252346335236 Explore P: 0.5144\n",
      "Episode: 190 Total reward: 6.051366648481369 Explore P: 0.5135\n",
      "Episode: 191 Total reward: 6.322660421492743 Explore P: 0.5125\n",
      "Episode: 192 Total reward: 11.509948939042985 Explore P: 0.5109\n",
      "Episode: 193 Total reward: 15.821179478829826 Explore P: 0.5090\n",
      "Episode: 194 Total reward: 4.323198055248671 Explore P: 0.5083\n",
      "Episode: 195 Total reward: 27.261142481680803 Explore P: 0.5051\n",
      "Episode: 196 Total reward: 8.032306059929992 Explore P: 0.5039\n",
      "Episode: 197 Total reward: 7.943543082909402 Explore P: 0.5026\n",
      "Episode: 198 Total reward: 5.987514371200389 Explore P: 0.5016\n",
      "Episode: 199 Total reward: 9.837216566620176 Explore P: 0.5003\n",
      "Episode: 200 Total reward: 11.930265541507156 Explore P: 0.4988\n",
      "Episode: 201 Total reward: 13.372976194205425 Explore P: 0.4970\n",
      "Episode: 202 Total reward: 4.919401903386293 Explore P: 0.4962\n",
      "Episode: 203 Total reward: 10.06601264292825 Explore P: 0.4949\n",
      "Episode: 204 Total reward: 31.021738456604872 Explore P: 0.4912\n",
      "Episode: 205 Total reward: 9.144031762249151 Explore P: 0.4900\n",
      "Episode: 206 Total reward: 5.047789517990685 Explore P: 0.4892\n",
      "Episode: 207 Total reward: 17.85626699214687 Explore P: 0.4869\n",
      "Episode: 208 Total reward: 11.366347443054124 Explore P: 0.4854\n",
      "Episode: 209 Total reward: 28.75598882338996 Explore P: 0.4819\n",
      "Episode: 210 Total reward: 28.391934242498415 Explore P: 0.4784\n",
      "Episode: 211 Total reward: 37.77350102359934 Explore P: 0.4737\n",
      "Episode: 212 Total reward: 14.36590024627454 Explore P: 0.4720\n",
      "Episode: 213 Total reward: 25.464055118827513 Explore P: 0.4687\n",
      "Episode: 214 Total reward: 33.14449640027739 Explore P: 0.4654\n",
      "Episode: 215 Total reward: 37.67984685862273 Explore P: 0.4610\n",
      "Episode: 216 Total reward: 21.01816833703298 Explore P: 0.4583\n",
      "Episode: 217 Total reward: 28.777226051876102 Explore P: 0.4547\n",
      "Episode: 218 Total reward: 22.073606832809077 Explore P: 0.4519\n",
      "Episode: 219 Total reward: 29.160705792952122 Explore P: 0.4480\n",
      "Episode: 220 Total reward: 37.56666738399559 Explore P: 0.4437\n",
      "Episode: 221 Total reward: 28.512025329500755 Explore P: 0.4402\n",
      "Episode: 222 Total reward: 29.138262843268944 Explore P: 0.4368\n",
      "Episode: 223 Total reward: 24.873805908622586 Explore P: 0.4344\n",
      "Episode: 224 Total reward: 34.15967936692455 Explore P: 0.4302\n",
      "Episode: 225 Total reward: 78.44708979716398 Explore P: 0.4220\n",
      "Episode: 226 Total reward: 32.03834436124374 Explore P: 0.4179\n",
      "Episode: 227 Total reward: 37.936583007180204 Explore P: 0.4145\n",
      "Episode: 228 Total reward: 26.148098048981293 Explore P: 0.4122\n",
      "Episode: 229 Total reward: 39.58102198656822 Explore P: 0.4087\n",
      "Episode: 230 Total reward: 57.31204299176094 Explore P: 0.4019\n",
      "Episode: 231 Total reward: 39.69165240841141 Explore P: 0.3983\n",
      "Episode: 232 Total reward: 38.291154179177376 Explore P: 0.3951\n",
      "Episode: 233 Total reward: 10.342283485519001 Explore P: 0.3942\n",
      "Episode: 234 Total reward: 24.854652542754653 Explore P: 0.3921\n",
      "Episode: 235 Total reward: 37.29450339576583 Explore P: 0.3889\n",
      "Episode: 236 Total reward: 15.834174290086615 Explore P: 0.3876\n",
      "Episode: 237 Total reward: 56.21317872613793 Explore P: 0.3827\n",
      "Episode: 238 Total reward: 46.340996715754514 Explore P: 0.3785\n",
      "Episode: 239 Total reward: 39.99670663885129 Explore P: 0.3749\n",
      "Episode: 240 Total reward: 52.207448327021545 Explore P: 0.3706\n",
      "Episode: 241 Total reward: 68.98567126105604 Explore P: 0.3651\n",
      "Episode: 242 Total reward: 49.394246127105134 Explore P: 0.3592\n",
      "Episode: 243 Total reward: 50.44526793136781 Explore P: 0.3553\n",
      "Episode: 244 Total reward: 52.9883597072961 Explore P: 0.3504\n",
      "Episode: 245 Total reward: 122.9890657123942 Explore P: 0.3395\n",
      "Episode: 246 Total reward: 78.52737734478015 Explore P: 0.3333\n",
      "Episode: 247 Total reward: 56.84250889311473 Explore P: 0.3288\n",
      "Episode: 248 Total reward: 44.87123550881464 Explore P: 0.3255\n",
      "Episode: 249 Total reward: 36.91150459312041 Explore P: 0.3230\n",
      "Episode: 250 Total reward: 63.49546059790718 Explore P: 0.3159\n",
      "Episode: 251 Total reward: 137.53273940703073 Explore P: 0.3065\n",
      "Episode: 252 Total reward: 37.527975662512326 Explore P: 0.3039\n",
      "Episode: 253 Total reward: 66.68718204204035 Explore P: 0.2996\n",
      "Episode: 254 Total reward: 65.83483575037397 Explore P: 0.2954\n",
      "Episode: 255 Total reward: 54.991136430556026 Explore P: 0.2917\n",
      "Episode: 256 Total reward: 100.67144186720296 Explore P: 0.2856\n",
      "Episode: 257 Total reward: 57.24778088626208 Explore P: 0.2822\n",
      "Episode: 258 Total reward: 39.7787273388725 Explore P: 0.2798\n",
      "Episode: 259 Total reward: 50.62753958217577 Explore P: 0.2766\n",
      "Episode: 260 Total reward: 144.1899916512496 Explore P: 0.2675\n",
      "Episode: 261 Total reward: 21.398434515124638 Explore P: 0.2663\n",
      "Episode: 262 Total reward: 54.78837171953302 Explore P: 0.2632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 263 Total reward: 52.54315692190404 Explore P: 0.2603\n",
      "Episode: 264 Total reward: 77.11932737785115 Explore P: 0.2560\n",
      "Episode: 265 Total reward: 49.86856616842749 Explore P: 0.2534\n",
      "Episode: 266 Total reward: 39.73574208703081 Explore P: 0.2511\n",
      "Episode: 267 Total reward: 85.02409577676079 Explore P: 0.2467\n",
      "Episode: 268 Total reward: 63.547026282666195 Explore P: 0.2432\n",
      "Episode: 269 Total reward: 65.61747170413058 Explore P: 0.2397\n",
      "Episode: 270 Total reward: 76.23366482387112 Explore P: 0.2357\n",
      "Episode: 271 Total reward: 50.35539767554037 Explore P: 0.2331\n",
      "Episode: 272 Total reward: 102.97955064176048 Explore P: 0.2276\n",
      "Episode: 273 Total reward: 37.53462455905208 Explore P: 0.2258\n",
      "Episode: 274 Total reward: 52.3971112086334 Explore P: 0.2233\n",
      "Episode: 275 Total reward: 77.20348882826545 Explore P: 0.2179\n",
      "Episode: 276 Total reward: 50.057640005085425 Explore P: 0.2156\n",
      "Episode: 277 Total reward: 26.219945169838663 Explore P: 0.2145\n",
      "Episode: 278 Total reward: 71.60738868712706 Explore P: 0.2112\n",
      "Episode: 279 Total reward: 51.25444173196248 Explore P: 0.2088\n",
      "Episode: 280 Total reward: 86.68036065366084 Explore P: 0.2049\n",
      "Episode: 281 Total reward: 63.52309344040956 Explore P: 0.2021\n",
      "Episode: 282 Total reward: 144.5938694895468 Explore P: 0.1960\n",
      "Episode: 283 Total reward: 32.720416294426656 Explore P: 0.1947\n",
      "Episode: 284 Total reward: 77.00052803618189 Explore P: 0.1915\n",
      "Episode: 285 Total reward: 48.24829161986234 Explore P: 0.1895\n",
      "Episode: 286 Total reward: 49.59838362543568 Explore P: 0.1875\n",
      "Episode: 287 Total reward: 82.47719486395339 Explore P: 0.1842\n",
      "Episode: 288 Total reward: 52.902569533691526 Explore P: 0.1820\n",
      "Episode: 289 Total reward: 58.78849978080767 Explore P: 0.1797\n",
      "Episode: 290 Total reward: 83.40767830272611 Explore P: 0.1765\n",
      "Episode: 291 Total reward: 56.35090909933489 Explore P: 0.1743\n",
      "Episode: 292 Total reward: 49.63825599436184 Explore P: 0.1724\n",
      "Episode: 293 Total reward: 72.8384873397811 Explore P: 0.1699\n",
      "Episode: 294 Total reward: 42.18475718499497 Explore P: 0.1684\n",
      "Episode: 295 Total reward: 37.99939320981275 Explore P: 0.1671\n",
      "Episode: 296 Total reward: 49.346245347322906 Explore P: 0.1654\n",
      "Episode: 297 Total reward: 95.60135823264017 Explore P: 0.1622\n",
      "Episode: 298 Total reward: 30.96379018230362 Explore P: 0.1612\n",
      "Episode: 299 Total reward: 35.702036050633986 Explore P: 0.1600\n",
      "Episode: 300 Total reward: 73.41113992896992 Explore P: 0.1571\n",
      "Episode: 301 Total reward: 88.38879554191625 Explore P: 0.1539\n",
      "Episode: 302 Total reward: 56.14073579311183 Explore P: 0.1521\n",
      "Episode: 303 Total reward: 98.73564631739666 Explore P: 0.1489\n",
      "Episode: 304 Total reward: 46.29492042229687 Explore P: 0.1474\n",
      "Episode: 305 Total reward: 92.1179389336789 Explore P: 0.1434\n",
      "Episode: 306 Total reward: 101.0301354727313 Explore P: 0.1401\n",
      "Episode: 307 Total reward: 95.79232986784763 Explore P: 0.1371\n",
      "Episode: 308 Total reward: 71.8055581050845 Explore P: 0.1339\n",
      "Episode: 309 Total reward: 70.34041515963415 Explore P: 0.1318\n",
      "Episode: 310 Total reward: 50.74019340661505 Explore P: 0.1304\n",
      "Episode: 311 Total reward: 40.90617145584199 Explore P: 0.1292\n",
      "Episode: 312 Total reward: 49.00956447591386 Explore P: 0.1268\n",
      "Episode: 313 Total reward: 61.12484046228463 Explore P: 0.1242\n",
      "Episode: 314 Total reward: 77.39955876873368 Explore P: 0.1212\n",
      "Episode: 315 Total reward: 90.24815355067618 Explore P: 0.1181\n",
      "Episode: 316 Total reward: 75.59189689837505 Explore P: 0.1154\n",
      "Episode: 317 Total reward: 109.3111097000133 Explore P: 0.1124\n",
      "Episode: 318 Total reward: 138.86659140186634 Explore P: 0.1083\n",
      "Episode: 319 Total reward: 130.43615961818472 Explore P: 0.1045\n",
      "Episode: 320 Total reward: 158.7312292215942 Explore P: 0.1006\n",
      "Episode: 321 Total reward: 82.56302407719572 Explore P: 0.0987\n",
      "Episode: 322 Total reward: 218.21264571675258 Explore P: 0.0937\n",
      "Episode: 323 Total reward: 95.53046963735792 Explore P: 0.0916\n",
      "Episode: 324 Total reward: 89.42770028990012 Explore P: 0.0897\n",
      "Episode: 325 Total reward: 141.88538389713838 Explore P: 0.0865\n",
      "Episode: 326 Total reward: 192.09530250938576 Explore P: 0.0826\n",
      "Episode: 327 Total reward: 121.1875048009214 Explore P: 0.0803\n",
      "Episode: 328 Total reward: 71.5051460519389 Explore P: 0.0789\n",
      "Episode: 329 Total reward: 166.1944953602042 Explore P: 0.0759\n",
      "Episode: 330 Total reward: 87.94202269773406 Explore P: 0.0744\n",
      "Episode: 331 Total reward: 100.21320475679336 Explore P: 0.0727\n",
      "Episode: 332 Total reward: 140.43423783272036 Explore P: 0.0706\n",
      "Episode: 333 Total reward: 142.18443618953336 Explore P: 0.0683\n",
      "Episode: 334 Total reward: 248.50860238324142 Explore P: 0.0647\n",
      "Episode: 335 Total reward: 313.9502004685194 Explore P: 0.0604\n",
      "Episode: 336 Total reward: 207.93830776233585 Explore P: 0.0579\n",
      "Episode: 337 Total reward: 187.93861833924095 Explore P: 0.0552\n",
      "Episode: 338 Total reward: 248.54344649871211 Explore P: 0.0525\n",
      "Episode: 339 Total reward: 188.4516192277263 Explore P: 0.0503\n",
      "Episode: 340 Total reward: 166.0825727339844 Explore P: 0.0486\n",
      "Episode: 341 Total reward: 335.6623740457959 Explore P: 0.0454\n",
      "Episode: 342 Total reward: 163.63230015155992 Explore P: 0.0439\n",
      "Episode: 343 Total reward: 162.2274293553908 Explore P: 0.0425\n",
      "Episode: 344 Total reward: 249.3166223516651 Explore P: 0.0405\n",
      "Episode: 345 Total reward: 384.79857093216225 Explore P: 0.0379\n",
      "Episode: 346 Total reward: 331.2195908501549 Explore P: 0.0356\n",
      "Episode: 347 Total reward: 241.4050884840318 Explore P: 0.0341\n",
      "Episode: 348 Total reward: 328.05599857779674 Explore P: 0.0321\n",
      "Episode: 349 Total reward: 416.5042958179481 Explore P: 0.0300\n",
      "Episode: 350 Total reward: 326.2554015829968 Explore P: 0.0284\n",
      "Episode: 351 Total reward: 444.1992673757033 Explore P: 0.0267\n",
      "Episode: 352 Total reward: 466.09718279035826 Explore P: 0.0251\n",
      "Episode: 353 Total reward: 460.7590697029987 Explore P: 0.0236\n",
      "Episode: 354 Total reward: 457.0589770448807 Explore P: 0.0223\n",
      "Episode: 355 Total reward: 466.536106433143 Explore P: 0.0212\n",
      "Episode: 356 Total reward: 465.7731870815369 Explore P: 0.0201\n",
      "Episode: 357 Total reward: 403.68925744173123 Explore P: 0.0192\n",
      "Episode: 358 Total reward: 419.42387858290994 Explore P: 0.0183\n",
      "Episode: 359 Total reward: 435.8235290682275 Explore P: 0.0175\n",
      "Episode: 360 Total reward: 477.03048031284027 Explore P: 0.0168\n",
      "Episode: 361 Total reward: 461.7437005641362 Explore P: 0.0161\n",
      "Episode: 362 Total reward: 439.7900556558666 Explore P: 0.0156\n",
      "Episode: 363 Total reward: 448.2344962959062 Explore P: 0.0150\n",
      "Episode: 364 Total reward: 441.49584644428154 Explore P: 0.0146\n",
      "Episode: 365 Total reward: 439.6336000676062 Explore P: 0.0141\n",
      "Episode: 366 Total reward: 456.37450513362654 Explore P: 0.0137\n",
      "Episode: 367 Total reward: 457.54773930243704 Explore P: 0.0134\n",
      "Episode: 368 Total reward: 468.52147645753263 Explore P: 0.0131\n",
      "Episode: 369 Total reward: 470.37958296028285 Explore P: 0.0128\n",
      "Episode: 370 Total reward: 476.247688769466 Explore P: 0.0125\n",
      "Episode: 371 Total reward: 459.46762493831534 Explore P: 0.0123\n",
      "Episode: 372 Total reward: 472.53513445919697 Explore P: 0.0120\n",
      "Episode: 373 Total reward: 478.01299810673777 Explore P: 0.0119\n",
      "Episode: 374 Total reward: 453.5729702389361 Explore P: 0.0117\n",
      "Episode: 375 Total reward: 468.8795767406383 Explore P: 0.0115\n",
      "Episode: 376 Total reward: 463.2374288956443 Explore P: 0.0114\n",
      "Episode: 377 Total reward: 455.72158615931687 Explore P: 0.0112\n",
      "Episode: 378 Total reward: 447.46449030446115 Explore P: 0.0111\n",
      "Episode: 379 Total reward: 466.61708739156126 Explore P: 0.0110\n",
      "Episode: 380 Total reward: 462.2028778234778 Explore P: 0.0109\n",
      "Episode: 381 Total reward: 453.3421381619201 Explore P: 0.0108\n",
      "Episode: 382 Total reward: 446.22334253201655 Explore P: 0.0108\n",
      "Episode: 383 Total reward: 462.07676425053774 Explore P: 0.0107\n",
      "Episode: 384 Total reward: 463.4345586596235 Explore P: 0.0106\n",
      "Episode: 385 Total reward: 458.1628848150044 Explore P: 0.0106\n",
      "Episode: 386 Total reward: 446.54716500654183 Explore P: 0.0105\n",
      "Episode: 387 Total reward: 474.74170557051224 Explore P: 0.0105\n",
      "Episode: 388 Total reward: 478.1405896298939 Explore P: 0.0104\n",
      "Episode: 389 Total reward: 456.23218157307036 Explore P: 0.0104\n",
      "Episode: 390 Total reward: 463.60710609841425 Explore P: 0.0103\n",
      "Episode: 391 Total reward: 474.6539487830281 Explore P: 0.0103\n",
      "Episode: 392 Total reward: 269.90204928099695 Explore P: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 393 Total reward: 461.1799694927329 Explore P: 0.0103\n",
      "Episode: 394 Total reward: 278.18240468492155 Explore P: 0.0102\n",
      "Episode: 395 Total reward: 477.45609194582426 Explore P: 0.0102\n",
      "Episode: 396 Total reward: 286.57013162241935 Explore P: 0.0102\n",
      "Episode: 397 Total reward: 197.3255542386364 Explore P: 0.0102\n",
      "Episode: 398 Total reward: 462.7588037255269 Explore P: 0.0102\n",
      "Episode: 399 Total reward: 429.45217616325306 Explore P: 0.0102\n",
      "Episode: 400 Total reward: 475.7537660118853 Explore P: 0.0101\n",
      "Episode: 401 Total reward: 477.39039740034275 Explore P: 0.0101\n",
      "Episode: 402 Total reward: 477.7855220745863 Explore P: 0.0101\n",
      "Episode: 403 Total reward: 473.2375398118335 Explore P: 0.0101\n",
      "Episode: 404 Total reward: 196.42458265796077 Explore P: 0.0101\n",
      "Episode: 405 Total reward: 473.788067363364 Explore P: 0.0101\n",
      "Episode: 406 Total reward: 463.8170045080021 Explore P: 0.0101\n",
      "Episode: 407 Total reward: 241.17299235599623 Explore P: 0.0101\n",
      "Episode: 408 Total reward: 478.32464336796295 Explore P: 0.0101\n",
      "Episode: 409 Total reward: 478.0580167898317 Explore P: 0.0101\n",
      "Episode: 410 Total reward: 460.808560115479 Explore P: 0.0101\n",
      "Episode: 411 Total reward: 461.4437542196088 Explore P: 0.0101\n",
      "Episode: 412 Total reward: 474.39379072846924 Explore P: 0.0100\n",
      "Episode: 413 Total reward: 318.0445287472636 Explore P: 0.0100\n",
      "Episode: 414 Total reward: 474.2478937001748 Explore P: 0.0100\n",
      "Episode: 415 Total reward: 308.4240459589515 Explore P: 0.0100\n",
      "Episode: 416 Total reward: 478.3683015657754 Explore P: 0.0100\n",
      "Episode: 417 Total reward: 473.26561687869224 Explore P: 0.0100\n",
      "Episode: 418 Total reward: 459.7071415681844 Explore P: 0.0100\n",
      "Episode: 419 Total reward: 477.00569372454333 Explore P: 0.0100\n",
      "Episode: 420 Total reward: 452.9899334354367 Explore P: 0.0100\n",
      "Episode: 421 Total reward: 327.2374551530051 Explore P: 0.0100\n",
      "Episode: 422 Total reward: 478.5195991039393 Explore P: 0.0100\n",
      "Episode: 423 Total reward: 456.88470294476883 Explore P: 0.0100\n",
      "Episode: 424 Total reward: 399.79848588849035 Explore P: 0.0100\n",
      "Episode: 425 Total reward: 320.7819480136772 Explore P: 0.0100\n",
      "Episode: 426 Total reward: 450.53465793025777 Explore P: 0.0100\n",
      "Episode: 427 Total reward: 333.8681310084745 Explore P: 0.0100\n",
      "Episode: 428 Total reward: 473.2800561264892 Explore P: 0.0100\n",
      "Episode: 429 Total reward: 234.38495907787728 Explore P: 0.0100\n",
      "Episode: 430 Total reward: 474.1714327310897 Explore P: 0.0100\n",
      "Episode: 431 Total reward: 305.8435281298982 Explore P: 0.0100\n",
      "Episode: 432 Total reward: 475.78177313084626 Explore P: 0.0100\n",
      "Episode: 433 Total reward: 347.9833982143367 Explore P: 0.0100\n",
      "Episode: 434 Total reward: 477.7618368282825 Explore P: 0.0100\n",
      "Episode: 435 Total reward: 475.5083305865136 Explore P: 0.0100\n",
      "Episode: 436 Total reward: 473.227568355402 Explore P: 0.0100\n",
      "Episode: 437 Total reward: 453.66138908843317 Explore P: 0.0100\n",
      "Episode: 438 Total reward: 476.37966319355667 Explore P: 0.0100\n",
      "Episode: 439 Total reward: 461.9854087599551 Explore P: 0.0100\n",
      "Episode: 440 Total reward: 256.2115510959742 Explore P: 0.0100\n",
      "Episode: 441 Total reward: 473.82355651830323 Explore P: 0.0100\n",
      "Episode: 442 Total reward: 471.2991668644049 Explore P: 0.0100\n",
      "Episode: 443 Total reward: 478.25431563778267 Explore P: 0.0100\n",
      "Episode: 444 Total reward: 473.5585053487697 Explore P: 0.0100\n",
      "Episode: 445 Total reward: 474.9955225653334 Explore P: 0.0100\n",
      "Episode: 446 Total reward: 458.48673220729813 Explore P: 0.0100\n",
      "Episode: 447 Total reward: 476.7792945487385 Explore P: 0.0100\n",
      "Episode: 448 Total reward: 457.48854907479677 Explore P: 0.0100\n",
      "Episode: 449 Total reward: 455.6026004003624 Explore P: 0.0100\n",
      "Episode: 450 Total reward: 474.55287490292545 Explore P: 0.0100\n",
      "Episode: 451 Total reward: 266.40830956058664 Explore P: 0.0100\n",
      "Episode: 452 Total reward: 474.3891569305758 Explore P: 0.0100\n",
      "Episode: 453 Total reward: 477.51380519530835 Explore P: 0.0100\n",
      "Episode: 454 Total reward: 453.6810156506028 Explore P: 0.0100\n",
      "Episode: 455 Total reward: 319.61066032628884 Explore P: 0.0100\n",
      "Episode: 456 Total reward: 459.8290252421168 Explore P: 0.0100\n",
      "Episode: 457 Total reward: 473.836908857049 Explore P: 0.0100\n",
      "Episode: 458 Total reward: 476.24141057320736 Explore P: 0.0100\n",
      "Episode: 459 Total reward: 477.16558864765074 Explore P: 0.0100\n",
      "Episode: 460 Total reward: 473.8072997268848 Explore P: 0.0100\n",
      "Episode: 461 Total reward: 473.7865924860961 Explore P: 0.0100\n",
      "Episode: 462 Total reward: 458.98755697522205 Explore P: 0.0100\n",
      "Episode: 463 Total reward: 229.05724724184597 Explore P: 0.0100\n",
      "Episode: 464 Total reward: 462.3802212960948 Explore P: 0.0100\n",
      "Episode: 465 Total reward: 451.4084964973007 Explore P: 0.0100\n",
      "Episode: 466 Total reward: 345.2445840626373 Explore P: 0.0100\n",
      "Episode: 467 Total reward: 475.92824694721673 Explore P: 0.0100\n",
      "Episode: 468 Total reward: 459.69299996649306 Explore P: 0.0100\n",
      "Episode: 469 Total reward: 459.2106991947902 Explore P: 0.0100\n",
      "Episode: 470 Total reward: 471.1404352939516 Explore P: 0.0100\n",
      "Episode: 471 Total reward: 343.6874597869891 Explore P: 0.0100\n",
      "Episode: 472 Total reward: 326.8955137594288 Explore P: 0.0100\n",
      "Episode: 473 Total reward: 368.51371817515803 Explore P: 0.0100\n",
      "Episode: 474 Total reward: 456.162550727946 Explore P: 0.0100\n",
      "Episode: 475 Total reward: 453.5860257022936 Explore P: 0.0100\n",
      "Episode: 476 Total reward: 469.34549715651167 Explore P: 0.0100\n",
      "Episode: 477 Total reward: 456.72954412937344 Explore P: 0.0100\n",
      "Episode: 478 Total reward: 476.20906401137375 Explore P: 0.0100\n",
      "Episode: 479 Total reward: 457.8489813718653 Explore P: 0.0100\n",
      "Episode: 480 Total reward: 322.49145855807205 Explore P: 0.0100\n",
      "Episode: 481 Total reward: 473.567315230471 Explore P: 0.0100\n",
      "Episode: 482 Total reward: 476.46199086328056 Explore P: 0.0100\n",
      "Episode: 483 Total reward: 455.2573554407436 Explore P: 0.0100\n",
      "Episode: 484 Total reward: 456.23939951796325 Explore P: 0.0100\n",
      "Episode: 485 Total reward: 473.25802344831266 Explore P: 0.0100\n",
      "Episode: 486 Total reward: 475.02587649373453 Explore P: 0.0100\n",
      "Episode: 487 Total reward: 296.11361436172234 Explore P: 0.0100\n",
      "Episode: 488 Total reward: 366.2736612904534 Explore P: 0.0100\n",
      "Episode: 489 Total reward: 456.9111615286649 Explore P: 0.0100\n",
      "Episode: 490 Total reward: 457.8003338993788 Explore P: 0.0100\n",
      "Episode: 491 Total reward: 380.98065412017473 Explore P: 0.0100\n",
      "Episode: 492 Total reward: 416.283216714594 Explore P: 0.0100\n",
      "Episode: 493 Total reward: 450.5761211684259 Explore P: 0.0100\n",
      "Episode: 494 Total reward: 358.8098891781581 Explore P: 0.0100\n",
      "Episode: 495 Total reward: 448.6377146487318 Explore P: 0.0100\n",
      "Episode: 496 Total reward: 453.0671577808766 Explore P: 0.0100\n",
      "Episode: 497 Total reward: 439.418168999706 Explore P: 0.0100\n",
      "Episode: 498 Total reward: 394.33421966095665 Explore P: 0.0100\n",
      "Episode: 499 Total reward: 447.5607717789955 Explore P: 0.0100\n",
      "Episode: 500 Total reward: 452.43903745716085 Explore P: 0.0100\n",
      "Episode: 501 Total reward: 446.991386619712 Explore P: 0.0100\n",
      "Episode: 502 Total reward: 440.0758967867509 Explore P: 0.0100\n",
      "Episode: 503 Total reward: 423.2385823497153 Explore P: 0.0100\n",
      "Episode: 504 Total reward: 449.8182416056525 Explore P: 0.0100\n",
      "Episode: 505 Total reward: 456.47387092213484 Explore P: 0.0100\n",
      "Episode: 506 Total reward: 455.37460585855723 Explore P: 0.0100\n",
      "Episode: 507 Total reward: 422.11129227995815 Explore P: 0.0100\n",
      "Episode: 508 Total reward: 455.51117606097245 Explore P: 0.0100\n",
      "Episode: 509 Total reward: 459.0007271404094 Explore P: 0.0100\n",
      "Episode: 510 Total reward: 477.3975066136743 Explore P: 0.0100\n",
      "Episode: 511 Total reward: 459.5860102362364 Explore P: 0.0100\n",
      "Episode: 512 Total reward: 462.18437126761967 Explore P: 0.0100\n",
      "Episode: 513 Total reward: 456.9818023108519 Explore P: 0.0100\n",
      "Episode: 514 Total reward: 453.15112642806395 Explore P: 0.0100\n",
      "Episode: 515 Total reward: 456.03263366834494 Explore P: 0.0100\n",
      "Episode: 516 Total reward: 476.0439469300552 Explore P: 0.0100\n",
      "Episode: 517 Total reward: 318.8568069383279 Explore P: 0.0100\n",
      "Episode: 518 Total reward: 334.73352330735025 Explore P: 0.0100\n",
      "Episode: 519 Total reward: 307.5484333997927 Explore P: 0.0100\n",
      "Episode: 520 Total reward: 383.17393873797135 Explore P: 0.0100\n",
      "Episode: 521 Total reward: 453.49335511700394 Explore P: 0.0100\n",
      "Episode: 522 Total reward: 460.85239129751636 Explore P: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 523 Total reward: 477.26507113137603 Explore P: 0.0100\n",
      "Episode: 524 Total reward: 460.60268306136 Explore P: 0.0100\n",
      "Episode: 525 Total reward: 453.1042407445478 Explore P: 0.0100\n",
      "Episode: 526 Total reward: 472.35003232778774 Explore P: 0.0100\n",
      "Episode: 527 Total reward: 476.80880691359226 Explore P: 0.0100\n",
      "Episode: 528 Total reward: 477.50938431020194 Explore P: 0.0100\n",
      "Episode: 529 Total reward: 477.84182481042507 Explore P: 0.0100\n",
      "Episode: 530 Total reward: 476.73260410187976 Explore P: 0.0100\n",
      "Episode: 531 Total reward: 477.4877749849227 Explore P: 0.0100\n",
      "Episode: 532 Total reward: 471.09326830947316 Explore P: 0.0100\n",
      "Episode: 533 Total reward: 473.23816418106395 Explore P: 0.0100\n",
      "Episode: 534 Total reward: 263.3818073163167 Explore P: 0.0100\n",
      "Episode: 535 Total reward: 476.316099129907 Explore P: 0.0100\n",
      "Episode: 536 Total reward: 461.74055906677654 Explore P: 0.0100\n",
      "Episode: 537 Total reward: 474.94311851957525 Explore P: 0.0100\n",
      "Episode: 538 Total reward: 464.7933701960604 Explore P: 0.0100\n",
      "Episode: 539 Total reward: 316.62652111601477 Explore P: 0.0100\n",
      "Episode: 540 Total reward: 454.94950950759363 Explore P: 0.0100\n",
      "Episode: 541 Total reward: 473.25694632967225 Explore P: 0.0100\n",
      "Episode: 542 Total reward: 466.1404306489791 Explore P: 0.0100\n",
      "Episode: 543 Total reward: 476.51357346474646 Explore P: 0.0100\n",
      "Episode: 544 Total reward: 321.13386447814844 Explore P: 0.0100\n",
      "Episode: 545 Total reward: 456.3452533332794 Explore P: 0.0100\n",
      "Episode: 546 Total reward: 474.4128050543325 Explore P: 0.0100\n",
      "Episode: 547 Total reward: 473.19690278075956 Explore P: 0.0100\n",
      "Episode: 548 Total reward: 474.2312517186616 Explore P: 0.0100\n",
      "Episode: 549 Total reward: 473.92778963899104 Explore P: 0.0100\n",
      "Episode: 550 Total reward: 478.28990335895287 Explore P: 0.0100\n",
      "Episode: 551 Total reward: 478.57598011151515 Explore P: 0.0100\n",
      "Episode: 552 Total reward: 475.11519844869383 Explore P: 0.0100\n",
      "Episode: 553 Total reward: 472.5950851782321 Explore P: 0.0100\n",
      "Episode: 554 Total reward: 470.9039558384181 Explore P: 0.0100\n",
      "Episode: 555 Total reward: 474.4322018620148 Explore P: 0.0100\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment these next 2 lines to watch the training\n",
    "            env.render() \n",
    "            sleep(0.0005)\n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # reduce the reward if the cart is not centered\n",
    "            reward = max(0, reward * (1 - abs(next_state[1]/2.4)))\n",
    "            if reward < 0 or reward > 1.0:\n",
    "                print(\"Reward: \", reward)\n",
    "                raise ValueError(\"reward is not in range\")\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        # if the agent gets 10 rewards bigger than 470 consecutively, stop the training\n",
    "        # 499 is never going to be reached because of the penalized reward\n",
    "        if len(rewards_list) > 10:\n",
    "            stop_training = False\n",
    "            for reward in rewards_list[-10:]:\n",
    "                if reward[1] < 470:\n",
    "                    break\n",
    "            else:\n",
    "                stop_training = True\n",
    "            if stop_training:\n",
    "                break\n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total Reward')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch a trained agent\n",
    "Note that the episode ends after 500 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_agent(n_episodes):\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        for episode in range(n_episodes):\n",
    "            state = env.reset()\n",
    "            r = 0\n",
    "            while True:\n",
    "                r += 1\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                env.render()\n",
    "                sleep(0.05)\n",
    "                # comment this if statement to see an endless episode\n",
    "                if done:\n",
    "                    env.close()\n",
    "                    print(f\"reward: {r}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n"
     ]
    }
   ],
   "source": [
    "watch_agent(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
