{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, I'll build a neural network that can learn to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](cart-pole.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions: 2\n",
      "States: Box(4,)\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# environment details\n",
    "print('Number of possible actions:', env.action_space.n)\n",
    "print('States:', env.observation_space)\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    env.render()\n",
    "    sleep(0.05)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. The network's goal is to maximize the reward by keeping the pole vertical.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "The neural network accepts a state $s$ as input and the output will be $Q$-values for each available action $a$.\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "Below is one implementation of the $Q$-network that uses 3 fully connected layers with ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        with tf.variable_scope(name):\n",
    "            # state inputs to the Q-network\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "            self.fc3 = tf.contrib.layers.fully_connected(self.fc2, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc3, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train using mean squared error and Adam gradient descent.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "This `Memory` object will store model's experience $<state, action, reward, next state>$. \n",
    "This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. \n",
    "Then, we'll sample a random mini-batch of transitions $<state, action, reward, next state>$ and train on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 700          # max number of episodes to learn from\n",
    "max_steps = 500               # max steps in an episode\n",
    "gamma = 1.0                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000            # memory capacity\n",
    "batch_size = 32                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "I re-initialize the simulation and pre-populate the memory in order to use later on the mini-batch.\n",
    "To do this the agent will take random actions and storing the transitions in memory.\n",
    "I also decided to modify the value of the reward in order to get a bigger reward if the cart stays centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    # reduce the reward if the cart is not centered\n",
    "    reward = reward * (1 - abs(next_state[1]/2.4))\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now it is time to train the agent.\n",
    "The training will stop automatically after 700 episodes or after 10 consecutive very high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 8.246317091450486 Training loss: 0.6986 Explore P: 0.9989\n",
      "Episode: 2 Total reward: 15.40829522818285 Training loss: 0.6801 Explore P: 0.9970\n",
      "Episode: 3 Total reward: 13.849846852581955 Training loss: 0.6975 Explore P: 0.9953\n",
      "Episode: 4 Total reward: 19.695408991808154 Training loss: 0.7599 Explore P: 0.9929\n",
      "Episode: 5 Total reward: 6.9062088401177295 Training loss: 0.7137 Explore P: 0.9918\n",
      "Episode: 6 Total reward: 12.223402383092745 Training loss: 0.7123 Explore P: 0.9903\n",
      "Episode: 7 Total reward: 19.4009216705791 Training loss: 0.7723 Explore P: 0.9882\n",
      "Episode: 8 Total reward: 12.702309639947655 Training loss: 0.8609 Explore P: 0.9865\n",
      "Episode: 9 Total reward: 9.59292925460581 Training loss: 0.8192 Explore P: 0.9852\n",
      "Episode: 10 Total reward: 10.953331802224165 Training loss: 0.7186 Explore P: 0.9838\n",
      "Episode: 11 Total reward: 22.735221342512876 Training loss: 0.9065 Explore P: 0.9812\n",
      "Episode: 12 Total reward: 11.773820618661382 Training loss: 1.0459 Explore P: 0.9797\n",
      "Episode: 13 Total reward: 26.35045230503437 Training loss: 0.9853 Explore P: 0.9768\n",
      "Episode: 14 Total reward: 11.835080498046926 Training loss: 1.5446 Explore P: 0.9755\n",
      "Episode: 15 Total reward: 7.943724240569554 Training loss: 1.3251 Explore P: 0.9742\n",
      "Episode: 16 Total reward: 19.77336772220584 Training loss: 3.9460 Explore P: 0.9716\n",
      "Episode: 17 Total reward: 18.995694348358562 Training loss: 4.9713 Explore P: 0.9695\n",
      "Episode: 18 Total reward: 10.376758289059802 Training loss: 1.3663 Explore P: 0.9682\n",
      "Episode: 19 Total reward: 14.987008129963957 Training loss: 2.4572 Explore P: 0.9663\n",
      "Episode: 20 Total reward: 9.077095486296137 Training loss: 4.5644 Explore P: 0.9651\n",
      "Episode: 21 Total reward: 14.16774455204828 Training loss: 2.2592 Explore P: 0.9634\n",
      "Episode: 22 Total reward: 10.591068458491247 Training loss: 5.4561 Explore P: 0.9620\n",
      "Episode: 23 Total reward: 12.574976335497228 Training loss: 12.1646 Explore P: 0.9603\n",
      "Episode: 24 Total reward: 8.22139231985743 Training loss: 5.4108 Explore P: 0.9593\n",
      "Episode: 25 Total reward: 26.436294338098556 Training loss: 18.9741 Explore P: 0.9562\n",
      "Episode: 26 Total reward: 8.457872268930174 Training loss: 7.1788 Explore P: 0.9551\n",
      "Episode: 27 Total reward: 29.14848596198253 Training loss: 4.9294 Explore P: 0.9521\n",
      "Episode: 28 Total reward: 15.167620180635552 Training loss: 12.7370 Explore P: 0.9499\n",
      "Episode: 29 Total reward: 11.430423843413882 Training loss: 44.7820 Explore P: 0.9486\n",
      "Episode: 30 Total reward: 5.772573491077102 Training loss: 58.9546 Explore P: 0.9478\n",
      "Episode: 31 Total reward: 9.774711156767582 Training loss: 24.3985 Explore P: 0.9465\n",
      "Episode: 32 Total reward: 19.364869011358287 Training loss: 11.4683 Explore P: 0.9443\n",
      "Episode: 33 Total reward: 39.770688445787044 Training loss: 53.8179 Explore P: 0.9385\n",
      "Episode: 34 Total reward: 8.116999872216056 Training loss: 30.8618 Explore P: 0.9374\n",
      "Episode: 35 Total reward: 7.802465020424714 Training loss: 13.7858 Explore P: 0.9364\n",
      "Episode: 36 Total reward: 16.47984485841217 Training loss: 73.7048 Explore P: 0.9347\n",
      "Episode: 37 Total reward: 10.352776247077356 Training loss: 33.4998 Explore P: 0.9334\n",
      "Episode: 38 Total reward: 8.359526781280035 Training loss: 87.9569 Explore P: 0.9322\n",
      "Episode: 39 Total reward: 12.383244579564812 Training loss: 41.2387 Explore P: 0.9309\n",
      "Episode: 40 Total reward: 9.952697442147064 Training loss: 117.8600 Explore P: 0.9296\n",
      "Episode: 41 Total reward: 37.98179610918649 Training loss: 31.2383 Explore P: 0.9253\n",
      "Episode: 42 Total reward: 9.675387507489484 Training loss: 95.7531 Explore P: 0.9242\n",
      "Episode: 43 Total reward: 12.585384454389047 Training loss: 105.4939 Explore P: 0.9227\n",
      "Episode: 44 Total reward: 13.243827770014757 Training loss: 71.7778 Explore P: 0.9211\n",
      "Episode: 45 Total reward: 29.647495351169926 Training loss: 42.8552 Explore P: 0.9181\n",
      "Episode: 46 Total reward: 9.91547766752275 Training loss: 109.8935 Explore P: 0.9169\n",
      "Episode: 47 Total reward: 27.091309387490746 Training loss: 84.5062 Explore P: 0.9141\n",
      "Episode: 48 Total reward: 12.511563048665833 Training loss: 228.4293 Explore P: 0.9126\n",
      "Episode: 49 Total reward: 35.642521789167915 Training loss: 121.9261 Explore P: 0.9075\n",
      "Episode: 50 Total reward: 33.28334212088002 Training loss: 308.0194 Explore P: 0.9039\n",
      "Episode: 51 Total reward: 17.596558148247947 Training loss: 144.6394 Explore P: 0.9021\n",
      "Episode: 52 Total reward: 17.737733553520705 Training loss: 21.5297 Explore P: 0.9003\n",
      "Episode: 53 Total reward: 20.709762407398262 Training loss: 299.9509 Explore P: 0.8981\n",
      "Episode: 54 Total reward: 20.54679048456131 Training loss: 156.0651 Explore P: 0.8960\n",
      "Episode: 55 Total reward: 17.916937932368565 Training loss: 55.7124 Explore P: 0.8942\n",
      "Episode: 56 Total reward: 19.286874699401235 Training loss: 348.6562 Explore P: 0.8920\n",
      "Episode: 57 Total reward: 20.211846017725836 Training loss: 295.1085 Explore P: 0.8899\n",
      "Episode: 58 Total reward: 12.58239370043488 Training loss: 115.9562 Explore P: 0.8885\n",
      "Episode: 59 Total reward: 18.346366310709847 Training loss: 87.6399 Explore P: 0.8863\n",
      "Episode: 60 Total reward: 8.461759441475861 Training loss: 77.3220 Explore P: 0.8852\n",
      "Episode: 61 Total reward: 9.84666453263362 Training loss: 52.3614 Explore P: 0.8840\n",
      "Episode: 62 Total reward: 11.37677189075474 Training loss: 41.7998 Explore P: 0.8828\n",
      "Episode: 63 Total reward: 17.18309646239363 Training loss: 231.0679 Explore P: 0.8809\n",
      "Episode: 64 Total reward: 7.321319406848416 Training loss: 314.3871 Explore P: 0.8800\n",
      "Episode: 65 Total reward: 27.765737649076975 Training loss: 134.2163 Explore P: 0.8767\n",
      "Episode: 66 Total reward: 21.271746782471894 Training loss: 1169.9740 Explore P: 0.8745\n",
      "Episode: 67 Total reward: 5.594105008122175 Training loss: 48.9349 Explore P: 0.8737\n",
      "Episode: 68 Total reward: 27.263441923593366 Training loss: 62.3503 Explore P: 0.8705\n",
      "Episode: 69 Total reward: 9.583547542515708 Training loss: 731.6829 Explore P: 0.8695\n",
      "Episode: 70 Total reward: 7.921352197458826 Training loss: 1047.2317 Explore P: 0.8685\n",
      "Episode: 71 Total reward: 28.209937454661663 Training loss: 579.3796 Explore P: 0.8658\n",
      "Episode: 72 Total reward: 28.443091254719 Training loss: 70.4736 Explore P: 0.8631\n",
      "Episode: 73 Total reward: 9.551660124134488 Training loss: 420.7172 Explore P: 0.8621\n",
      "Episode: 74 Total reward: 5.86897069745746 Training loss: 698.5458 Explore P: 0.8612\n",
      "Episode: 75 Total reward: 11.993837564089262 Training loss: 307.0345 Explore P: 0.8601\n",
      "Episode: 76 Total reward: 7.573507634988841 Training loss: 1456.6472 Explore P: 0.8592\n",
      "Episode: 77 Total reward: 11.758313777282542 Training loss: 591.7701 Explore P: 0.8580\n",
      "Episode: 78 Total reward: 5.16758400443978 Training loss: 699.3500 Explore P: 0.8573\n",
      "Episode: 79 Total reward: 7.448349004240706 Training loss: 66.0618 Explore P: 0.8564\n",
      "Episode: 80 Total reward: 15.116827081796997 Training loss: 1985.2843 Explore P: 0.8549\n",
      "Episode: 81 Total reward: 11.462710371966407 Training loss: 2378.5222 Explore P: 0.8536\n",
      "Episode: 82 Total reward: 17.442871781742905 Training loss: 748.1838 Explore P: 0.8519\n",
      "Episode: 83 Total reward: 20.04747512405978 Training loss: 478.4518 Explore P: 0.8501\n",
      "Episode: 84 Total reward: 16.746534990726985 Training loss: 1034.4004 Explore P: 0.8483\n",
      "Episode: 85 Total reward: 32.23146879244475 Training loss: 1121.2067 Explore P: 0.8452\n",
      "Episode: 86 Total reward: 23.06695393978922 Training loss: 1031.8990 Explore P: 0.8431\n",
      "Episode: 87 Total reward: 7.488542672018643 Training loss: 1169.4337 Explore P: 0.8421\n",
      "Episode: 88 Total reward: 14.09115463956058 Training loss: 33.0871 Explore P: 0.8406\n",
      "Episode: 89 Total reward: 6.7932584074545375 Training loss: 1350.7823 Explore P: 0.8397\n",
      "Episode: 90 Total reward: 24.697824883107277 Training loss: 763.2711 Explore P: 0.8374\n",
      "Episode: 91 Total reward: 8.848495223116043 Training loss: 21.5718 Explore P: 0.8364\n",
      "Episode: 92 Total reward: 28.969411993058028 Training loss: 1112.5876 Explore P: 0.8338\n",
      "Episode: 93 Total reward: 11.431145329295692 Training loss: 318.0955 Explore P: 0.8325\n",
      "Episode: 94 Total reward: 14.941970591747546 Training loss: 333.3405 Explore P: 0.8311\n",
      "Episode: 95 Total reward: 27.220846142436454 Training loss: 660.6605 Explore P: 0.8276\n",
      "Episode: 96 Total reward: 19.99812867287699 Training loss: 587.1628 Explore P: 0.8254\n",
      "Episode: 97 Total reward: 35.33955945322337 Training loss: 816.3875 Explore P: 0.8220\n",
      "Episode: 98 Total reward: 17.079676365306753 Training loss: 303.5959 Explore P: 0.8201\n",
      "Episode: 99 Total reward: 8.19723974338506 Training loss: 753.2191 Explore P: 0.8192\n",
      "Episode: 100 Total reward: 18.36714593781419 Training loss: 219.6793 Explore P: 0.8174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 101 Total reward: 11.01536431488566 Training loss: 292.9176 Explore P: 0.8163\n",
      "Episode: 102 Total reward: 7.021814129220322 Training loss: 469.7413 Explore P: 0.8154\n",
      "Episode: 103 Total reward: 20.92217197992353 Training loss: 9.5861 Explore P: 0.8133\n",
      "Episode: 104 Total reward: 12.045982783188354 Training loss: 207.7788 Explore P: 0.8121\n",
      "Episode: 105 Total reward: 23.027809673792984 Training loss: 749.9335 Explore P: 0.8101\n",
      "Episode: 106 Total reward: 32.74156192167037 Training loss: 240.7744 Explore P: 0.8071\n",
      "Episode: 107 Total reward: 16.46661285326673 Training loss: 233.3514 Explore P: 0.8055\n",
      "Episode: 108 Total reward: 10.871433341024682 Training loss: 6.5624 Explore P: 0.8044\n",
      "Episode: 109 Total reward: 7.224559760880059 Training loss: 6.3989 Explore P: 0.8035\n",
      "Episode: 110 Total reward: 15.522351158653853 Training loss: 600.9084 Explore P: 0.8021\n",
      "Episode: 111 Total reward: 8.589511885502866 Training loss: 326.6425 Explore P: 0.8012\n",
      "Episode: 112 Total reward: 22.120060940451292 Training loss: 8.2805 Explore P: 0.7990\n",
      "Episode: 113 Total reward: 9.784636213925822 Training loss: 577.6058 Explore P: 0.7980\n",
      "Episode: 114 Total reward: 4.447223034578683 Training loss: 677.9648 Explore P: 0.7974\n",
      "Episode: 115 Total reward: 19.048984176174578 Training loss: 7.1290 Explore P: 0.7957\n",
      "Episode: 116 Total reward: 11.670706686501838 Training loss: 441.3233 Explore P: 0.7946\n",
      "Episode: 117 Total reward: 4.891829265637076 Training loss: 7.5287 Explore P: 0.7939\n",
      "Episode: 118 Total reward: 5.674588485489657 Training loss: 6.3340 Explore P: 0.7933\n",
      "Episode: 119 Total reward: 11.389005637025978 Training loss: 3.9504 Explore P: 0.7922\n",
      "Episode: 120 Total reward: 9.220072552135537 Training loss: 5.7974 Explore P: 0.7912\n",
      "Episode: 121 Total reward: 13.910326299794713 Training loss: 368.1076 Explore P: 0.7898\n",
      "Episode: 122 Total reward: 12.009223350748078 Training loss: 165.3834 Explore P: 0.7885\n",
      "Episode: 123 Total reward: 7.112116157344578 Training loss: 94.8063 Explore P: 0.7877\n",
      "Episode: 124 Total reward: 7.1330900580270145 Training loss: 5.5130 Explore P: 0.7869\n",
      "Episode: 125 Total reward: 13.278351712540944 Training loss: 266.6125 Explore P: 0.7855\n",
      "Episode: 126 Total reward: 9.819179161209979 Training loss: 97.4386 Explore P: 0.7844\n",
      "Episode: 127 Total reward: 19.978090206540358 Training loss: 391.1622 Explore P: 0.7821\n",
      "Episode: 128 Total reward: 9.431666651148362 Training loss: 7.2592 Explore P: 0.7810\n",
      "Episode: 129 Total reward: 8.061022113061808 Training loss: 225.0152 Explore P: 0.7801\n",
      "Episode: 130 Total reward: 4.386941475629523 Training loss: 438.9044 Explore P: 0.7795\n",
      "Episode: 131 Total reward: 18.23912472733891 Training loss: 86.5476 Explore P: 0.7778\n",
      "Episode: 132 Total reward: 10.561377391126678 Training loss: 69.5666 Explore P: 0.7767\n",
      "Episode: 133 Total reward: 10.195175701099773 Training loss: 65.4816 Explore P: 0.7756\n",
      "Episode: 134 Total reward: 16.320894687815954 Training loss: 131.8384 Explore P: 0.7741\n",
      "Episode: 135 Total reward: 17.828286691328202 Training loss: 157.3244 Explore P: 0.7726\n",
      "Episode: 136 Total reward: 7.6830449651489126 Training loss: 8.3423 Explore P: 0.7717\n",
      "Episode: 137 Total reward: 11.134408335998307 Training loss: 120.5946 Explore P: 0.7707\n",
      "Episode: 138 Total reward: 10.138707404879039 Training loss: 57.1781 Explore P: 0.7697\n",
      "Episode: 139 Total reward: 35.16534581456056 Training loss: 6.9237 Explore P: 0.7651\n",
      "Episode: 140 Total reward: 5.86320528603142 Training loss: 10.8844 Explore P: 0.7645\n",
      "Episode: 141 Total reward: 8.806919257752103 Training loss: 7.8103 Explore P: 0.7636\n",
      "Episode: 142 Total reward: 6.416040923055581 Training loss: 10.2098 Explore P: 0.7628\n",
      "Episode: 143 Total reward: 7.373729143010072 Training loss: 95.6747 Explore P: 0.7620\n",
      "Episode: 144 Total reward: 23.533066753904873 Training loss: 78.3026 Explore P: 0.7600\n",
      "Episode: 145 Total reward: 13.188489073976317 Training loss: 42.5540 Explore P: 0.7588\n",
      "Episode: 146 Total reward: 10.694651581875897 Training loss: 69.0198 Explore P: 0.7578\n",
      "Episode: 147 Total reward: 10.998473808164235 Training loss: 161.9212 Explore P: 0.7567\n",
      "Episode: 148 Total reward: 15.27011973652881 Training loss: 172.0130 Explore P: 0.7554\n",
      "Episode: 149 Total reward: 13.744474776688886 Training loss: 67.6132 Explore P: 0.7540\n",
      "Episode: 150 Total reward: 7.768735095719577 Training loss: 75.7721 Explore P: 0.7532\n",
      "Episode: 151 Total reward: 19.185292976633864 Training loss: 9.2592 Explore P: 0.7515\n",
      "Episode: 152 Total reward: 9.967817107595648 Training loss: 34.7742 Explore P: 0.7505\n",
      "Episode: 153 Total reward: 17.630279986311344 Training loss: 185.1706 Explore P: 0.7489\n",
      "Episode: 154 Total reward: 15.059946096604731 Training loss: 36.4828 Explore P: 0.7475\n",
      "Episode: 155 Total reward: 33.03317592344786 Training loss: 8.4517 Explore P: 0.7444\n",
      "Episode: 156 Total reward: 12.928789438830268 Training loss: 175.2723 Explore P: 0.7431\n",
      "Episode: 157 Total reward: 9.98666281003039 Training loss: 40.0164 Explore P: 0.7422\n",
      "Episode: 158 Total reward: 13.093980647566594 Training loss: 237.6115 Explore P: 0.7408\n",
      "Episode: 159 Total reward: 34.001790392211326 Training loss: 119.3591 Explore P: 0.7378\n",
      "Episode: 160 Total reward: 12.204544469727745 Training loss: 156.4950 Explore P: 0.7365\n",
      "Episode: 161 Total reward: 4.850120084529967 Training loss: 227.8853 Explore P: 0.7359\n",
      "Episode: 162 Total reward: 28.340877256124507 Training loss: 11.9625 Explore P: 0.7336\n",
      "Episode: 163 Total reward: 14.610023812868183 Training loss: 11.8668 Explore P: 0.7324\n",
      "Episode: 164 Total reward: 39.59020968277571 Training loss: 214.8270 Explore P: 0.7290\n",
      "Episode: 165 Total reward: 6.943118465718765 Training loss: 8.5780 Explore P: 0.7283\n",
      "Episode: 166 Total reward: 12.773654918674026 Training loss: 152.8285 Explore P: 0.7272\n",
      "Episode: 167 Total reward: 7.374997389972994 Training loss: 224.3831 Explore P: 0.7265\n",
      "Episode: 168 Total reward: 14.89739412886626 Training loss: 211.4240 Explore P: 0.7252\n",
      "Episode: 169 Total reward: 15.448049493209686 Training loss: 62.8781 Explore P: 0.7237\n",
      "Episode: 170 Total reward: 11.686227901393247 Training loss: 142.3873 Explore P: 0.7227\n",
      "Episode: 171 Total reward: 12.209423760294479 Training loss: 126.0782 Explore P: 0.7217\n",
      "Episode: 172 Total reward: 11.718704007560227 Training loss: 41.4661 Explore P: 0.7204\n",
      "Episode: 173 Total reward: 6.551976220990914 Training loss: 53.1510 Explore P: 0.7197\n",
      "Episode: 174 Total reward: 18.846761013224587 Training loss: 121.1105 Explore P: 0.7181\n",
      "Episode: 175 Total reward: 22.79084117559722 Training loss: 216.8504 Explore P: 0.7162\n",
      "Episode: 176 Total reward: 17.958491792251603 Training loss: 294.4766 Explore P: 0.7147\n",
      "Episode: 177 Total reward: 14.176735316131692 Training loss: 31.8440 Explore P: 0.7133\n",
      "Episode: 178 Total reward: 8.118584243885344 Training loss: 12.1798 Explore P: 0.7125\n",
      "Episode: 179 Total reward: 29.940173990745386 Training loss: 43.6965 Explore P: 0.7101\n",
      "Episode: 180 Total reward: 7.849666966096709 Training loss: 116.8244 Explore P: 0.7092\n",
      "Episode: 181 Total reward: 9.070195433549207 Training loss: 62.0597 Explore P: 0.7084\n",
      "Episode: 182 Total reward: 12.653999417725066 Training loss: 59.3960 Explore P: 0.7074\n",
      "Episode: 183 Total reward: 17.70649564453066 Training loss: 11.6803 Explore P: 0.7060\n",
      "Episode: 184 Total reward: 5.917411030601695 Training loss: 99.2310 Explore P: 0.7053\n",
      "Episode: 185 Total reward: 6.204275473383191 Training loss: 36.2860 Explore P: 0.7047\n",
      "Episode: 186 Total reward: 12.923836763820837 Training loss: 122.5488 Explore P: 0.7035\n",
      "Episode: 187 Total reward: 14.526451422897798 Training loss: 42.5552 Explore P: 0.7024\n",
      "Episode: 188 Total reward: 11.485072671405003 Training loss: 6.6909 Explore P: 0.7013\n",
      "Episode: 189 Total reward: 9.149740863456493 Training loss: 118.2105 Explore P: 0.7004\n",
      "Episode: 190 Total reward: 17.52475818909163 Training loss: 165.6348 Explore P: 0.6988\n",
      "Episode: 191 Total reward: 12.968980570728572 Training loss: 84.2088 Explore P: 0.6976\n",
      "Episode: 192 Total reward: 30.09129330836575 Training loss: 5.9333 Explore P: 0.6949\n",
      "Episode: 193 Total reward: 4.0819575954164495 Training loss: 178.8406 Explore P: 0.6944\n",
      "Episode: 194 Total reward: 6.667969203247871 Training loss: 105.9635 Explore P: 0.6936\n",
      "Episode: 195 Total reward: 6.160751823168136 Training loss: 156.2849 Explore P: 0.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 196 Total reward: 4.252963183920012 Training loss: 115.3390 Explore P: 0.6924\n",
      "Episode: 197 Total reward: 29.549523078264333 Training loss: 22.0886 Explore P: 0.6901\n",
      "Episode: 198 Total reward: 7.558781926756502 Training loss: 122.9487 Explore P: 0.6894\n",
      "Episode: 199 Total reward: 6.556440962818117 Training loss: 266.0793 Explore P: 0.6887\n",
      "Episode: 200 Total reward: 12.006727865816773 Training loss: 4.3585 Explore P: 0.6875\n",
      "Episode: 201 Total reward: 11.448467412085321 Training loss: 7.8339 Explore P: 0.6865\n",
      "Episode: 202 Total reward: 10.509550774167367 Training loss: 58.4925 Explore P: 0.6856\n",
      "Episode: 203 Total reward: 64.70150304088239 Training loss: 3.8511 Explore P: 0.6804\n",
      "Episode: 204 Total reward: 48.62919895958013 Training loss: 36.6457 Explore P: 0.6767\n",
      "Episode: 205 Total reward: 51.87286728706349 Training loss: 85.7449 Explore P: 0.6727\n",
      "Episode: 206 Total reward: 80.88673397075792 Training loss: 43.3524 Explore P: 0.6668\n",
      "Episode: 207 Total reward: 31.593502010300117 Training loss: 25.5363 Explore P: 0.6645\n",
      "Episode: 208 Total reward: 22.310488966820007 Training loss: 11.0369 Explore P: 0.6628\n",
      "Episode: 209 Total reward: 17.206613507429076 Training loss: 4.3322 Explore P: 0.6615\n",
      "Episode: 210 Total reward: 44.69625990946013 Training loss: 4.2224 Explore P: 0.6583\n",
      "Episode: 211 Total reward: 42.72121044621926 Training loss: 4.5966 Explore P: 0.6547\n",
      "Episode: 212 Total reward: 22.928493139008182 Training loss: 5.6920 Explore P: 0.6531\n",
      "Episode: 213 Total reward: 74.01827173033953 Training loss: 51.9583 Explore P: 0.6480\n",
      "Episode: 214 Total reward: 23.84822110353934 Training loss: 60.4205 Explore P: 0.6461\n",
      "Episode: 215 Total reward: 35.71699406286426 Training loss: 57.7952 Explore P: 0.6436\n",
      "Episode: 216 Total reward: 40.50855359543264 Training loss: 5.6037 Explore P: 0.6408\n",
      "Episode: 217 Total reward: 60.53551809797718 Training loss: 25.4968 Explore P: 0.6358\n",
      "Episode: 218 Total reward: 48.89710672582021 Training loss: 4.9143 Explore P: 0.6309\n",
      "Episode: 219 Total reward: 33.54912816749943 Training loss: 85.4542 Explore P: 0.6285\n",
      "Episode: 220 Total reward: 25.831413631545868 Training loss: 7.5351 Explore P: 0.6268\n",
      "Episode: 221 Total reward: 10.760067352994959 Training loss: 83.9991 Explore P: 0.6259\n",
      "Episode: 222 Total reward: 11.829520198491483 Training loss: 43.1418 Explore P: 0.6250\n",
      "Episode: 223 Total reward: 39.0854750590992 Training loss: 82.9221 Explore P: 0.6223\n",
      "Episode: 224 Total reward: 11.871175796129819 Training loss: 50.5288 Explore P: 0.6214\n",
      "Episode: 225 Total reward: 41.614492887416816 Training loss: 42.7830 Explore P: 0.6186\n",
      "Episode: 226 Total reward: 33.03478218803393 Training loss: 102.7124 Explore P: 0.6160\n",
      "Episode: 227 Total reward: 23.14733458654308 Training loss: 59.6606 Explore P: 0.6144\n",
      "Episode: 228 Total reward: 50.74492864204139 Training loss: 71.3612 Explore P: 0.6110\n",
      "Episode: 229 Total reward: 21.220566366524153 Training loss: 36.7565 Explore P: 0.6096\n",
      "Episode: 230 Total reward: 11.511276825554415 Training loss: 58.7693 Explore P: 0.6087\n",
      "Episode: 231 Total reward: 40.26954361439155 Training loss: 67.7651 Explore P: 0.6062\n",
      "Episode: 232 Total reward: 20.49865180035018 Training loss: 31.4317 Explore P: 0.6048\n",
      "Episode: 233 Total reward: 42.818835161828645 Training loss: 35.0579 Explore P: 0.6020\n",
      "Episode: 234 Total reward: 27.164457910446206 Training loss: 37.8210 Explore P: 0.6003\n",
      "Episode: 235 Total reward: 25.701014541267305 Training loss: 49.8854 Explore P: 0.5986\n",
      "Episode: 236 Total reward: 16.6495597134686 Training loss: 102.7188 Explore P: 0.5975\n",
      "Episode: 237 Total reward: 7.71319307338422 Training loss: 74.7101 Explore P: 0.5968\n",
      "Episode: 238 Total reward: 32.43937010740891 Training loss: 86.6261 Explore P: 0.5948\n",
      "Episode: 239 Total reward: 33.41825529352675 Training loss: 54.3006 Explore P: 0.5925\n",
      "Episode: 240 Total reward: 27.15273438125941 Training loss: 3.3170 Explore P: 0.5907\n",
      "Episode: 241 Total reward: 25.174077413943785 Training loss: 58.4447 Explore P: 0.5891\n",
      "Episode: 242 Total reward: 21.790163301536893 Training loss: 39.2068 Explore P: 0.5877\n",
      "Episode: 243 Total reward: 33.787849289056055 Training loss: 244.1331 Explore P: 0.5855\n",
      "Episode: 244 Total reward: 42.89704399134505 Training loss: 9.6638 Explore P: 0.5828\n",
      "Episode: 245 Total reward: 70.35334806743282 Training loss: 6.8579 Explore P: 0.5780\n",
      "Episode: 246 Total reward: 29.843417615548 Training loss: 201.2365 Explore P: 0.5761\n",
      "Episode: 247 Total reward: 37.58848714178096 Training loss: 73.7654 Explore P: 0.5736\n",
      "Episode: 248 Total reward: 46.55083115291543 Training loss: 141.8633 Explore P: 0.5705\n",
      "Episode: 249 Total reward: 10.052094686908298 Training loss: 61.1085 Explore P: 0.5698\n",
      "Episode: 250 Total reward: 47.11177918871733 Training loss: 185.9849 Explore P: 0.5668\n",
      "Episode: 251 Total reward: 31.56976191559496 Training loss: 112.8090 Explore P: 0.5649\n",
      "Episode: 252 Total reward: 56.85500833599224 Training loss: 182.3718 Explore P: 0.5611\n",
      "Episode: 253 Total reward: 53.130377271904536 Training loss: 46.6962 Explore P: 0.5580\n",
      "Episode: 254 Total reward: 15.646611820928566 Training loss: 78.4146 Explore P: 0.5570\n",
      "Episode: 255 Total reward: 11.585757284316465 Training loss: 165.7270 Explore P: 0.5562\n",
      "Episode: 256 Total reward: 65.31255648102827 Training loss: 62.1807 Explore P: 0.5520\n",
      "Episode: 257 Total reward: 24.161313722924966 Training loss: 46.1000 Explore P: 0.5505\n",
      "Episode: 258 Total reward: 45.34922880347042 Training loss: 8.0701 Explore P: 0.5478\n",
      "Episode: 259 Total reward: 9.22298478691968 Training loss: 14.1567 Explore P: 0.5472\n",
      "Episode: 260 Total reward: 44.08047383770561 Training loss: 11.7528 Explore P: 0.5444\n",
      "Episode: 261 Total reward: 24.250782044429958 Training loss: 78.3617 Explore P: 0.5429\n",
      "Episode: 262 Total reward: 74.18138690889066 Training loss: 55.1460 Explore P: 0.5383\n",
      "Episode: 263 Total reward: 50.5511047042258 Training loss: 360.4293 Explore P: 0.5346\n",
      "Episode: 264 Total reward: 41.11668043019773 Training loss: 106.5285 Explore P: 0.5321\n",
      "Episode: 265 Total reward: 115.66366229409581 Training loss: 6.9338 Explore P: 0.5252\n",
      "Episode: 266 Total reward: 52.34879527012958 Training loss: 65.7925 Explore P: 0.5221\n",
      "Episode: 267 Total reward: 25.81194627216258 Training loss: 306.3979 Explore P: 0.5207\n",
      "Episode: 268 Total reward: 36.725900939417734 Training loss: 23.5108 Explore P: 0.5185\n",
      "Episode: 269 Total reward: 36.834949864575435 Training loss: 16.3561 Explore P: 0.5163\n",
      "Episode: 270 Total reward: 54.89815062823528 Training loss: 11.3289 Explore P: 0.5133\n",
      "Episode: 271 Total reward: 44.40391822175705 Training loss: 136.6243 Explore P: 0.5102\n",
      "Episode: 272 Total reward: 27.016210408772636 Training loss: 143.4278 Explore P: 0.5087\n",
      "Episode: 273 Total reward: 99.01862203145446 Training loss: 16.9536 Explore P: 0.5033\n",
      "Episode: 274 Total reward: 39.675352599719474 Training loss: 9.1123 Explore P: 0.5010\n",
      "Episode: 275 Total reward: 82.69718206626884 Training loss: 235.8362 Explore P: 0.4963\n",
      "Episode: 276 Total reward: 14.961743232917664 Training loss: 447.8970 Explore P: 0.4954\n",
      "Episode: 277 Total reward: 47.27713513592928 Training loss: 194.8424 Explore P: 0.4927\n",
      "Episode: 278 Total reward: 52.29619717731793 Training loss: 63.5218 Explore P: 0.4899\n",
      "Episode: 279 Total reward: 68.23417274073518 Training loss: 14.6406 Explore P: 0.4862\n",
      "Episode: 280 Total reward: 89.76514437718139 Training loss: 9.7783 Explore P: 0.4814\n",
      "Episode: 281 Total reward: 33.626014732970376 Training loss: 131.6212 Explore P: 0.4797\n",
      "Episode: 282 Total reward: 73.30210194785677 Training loss: 13.1354 Explore P: 0.4759\n",
      "Episode: 283 Total reward: 46.01648973581062 Training loss: 273.6724 Explore P: 0.4735\n",
      "Episode: 284 Total reward: 77.27279593088016 Training loss: 200.6870 Explore P: 0.4690\n",
      "Episode: 285 Total reward: 70.97431324710747 Training loss: 130.6117 Explore P: 0.4654\n",
      "Episode: 286 Total reward: 82.95185347121507 Training loss: 25.9593 Explore P: 0.4599\n",
      "Episode: 287 Total reward: 78.26352337820296 Training loss: 155.9858 Explore P: 0.4542\n",
      "Episode: 288 Total reward: 14.345397115664026 Training loss: 122.9535 Explore P: 0.4534\n",
      "Episode: 289 Total reward: 46.7413621655027 Training loss: 1345.6599 Explore P: 0.4511\n",
      "Episode: 290 Total reward: 109.2747097583523 Training loss: 18.7103 Explore P: 0.4455\n",
      "Episode: 291 Total reward: 53.20302686304188 Training loss: 45.7276 Explore P: 0.4429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 292 Total reward: 193.20715882621087 Training loss: 588.8953 Explore P: 0.4323\n",
      "Episode: 293 Total reward: 122.41442298949217 Training loss: 384.8250 Explore P: 0.4251\n",
      "Episode: 294 Total reward: 163.48188064962164 Training loss: 1049.4978 Explore P: 0.4162\n",
      "Episode: 295 Total reward: 114.66599334983353 Training loss: 1301.5525 Explore P: 0.4106\n",
      "Episode: 296 Total reward: 115.50425654377196 Training loss: 30.0586 Explore P: 0.4046\n",
      "Episode: 297 Total reward: 45.21544744833934 Training loss: 325.2166 Explore P: 0.4024\n",
      "Episode: 298 Total reward: 75.28203402813797 Training loss: 38.3799 Explore P: 0.3988\n",
      "Episode: 299 Total reward: 55.991047482826026 Training loss: 163.2910 Explore P: 0.3964\n",
      "Episode: 300 Total reward: 61.319325294913995 Training loss: 21.7974 Explore P: 0.3938\n",
      "Episode: 301 Total reward: 107.07158198192462 Training loss: 22.6598 Explore P: 0.3892\n",
      "Episode: 302 Total reward: 145.77494859038785 Training loss: 319.9487 Explore P: 0.3817\n",
      "Episode: 303 Total reward: 227.27310725402123 Training loss: 56.4114 Explore P: 0.3715\n",
      "Episode: 304 Total reward: 194.2837923866599 Training loss: 1219.2197 Explore P: 0.3633\n",
      "Episode: 305 Total reward: 200.24311865017927 Training loss: 656.3889 Explore P: 0.3538\n",
      "Episode: 306 Total reward: 82.23849981722326 Training loss: 1547.6724 Explore P: 0.3488\n",
      "Episode: 307 Total reward: 247.1636036014063 Training loss: 734.5850 Explore P: 0.3388\n",
      "Episode: 308 Total reward: 330.53059552839227 Training loss: 1568.2156 Explore P: 0.3264\n",
      "Episode: 309 Total reward: 163.5100372139528 Training loss: 1311.9381 Explore P: 0.3195\n",
      "Episode: 310 Total reward: 415.0681058582535 Training loss: 939.5185 Explore P: 0.3045\n",
      "Episode: 311 Total reward: 133.83920804284102 Training loss: 1790.0780 Explore P: 0.2991\n",
      "Episode: 312 Total reward: 138.45453998744506 Training loss: 70.4259 Explore P: 0.2936\n",
      "Episode: 313 Total reward: 162.2623412445891 Training loss: 593.5872 Explore P: 0.2876\n",
      "Episode: 314 Total reward: 286.071656188947 Training loss: 703.5676 Explore P: 0.2782\n",
      "Episode: 315 Total reward: 185.38551777758906 Training loss: 585.9893 Explore P: 0.2719\n",
      "Episode: 316 Total reward: 135.51499541682932 Training loss: 89.8019 Explore P: 0.2669\n",
      "Episode: 317 Total reward: 148.26134309442384 Training loss: 246.3066 Explore P: 0.2618\n",
      "Episode: 318 Total reward: 117.83228666895079 Training loss: 143.3853 Explore P: 0.2575\n",
      "Episode: 319 Total reward: 193.3721511917631 Training loss: 231.9755 Explore P: 0.2514\n",
      "Episode: 320 Total reward: 86.83729226888704 Training loss: 1011.2097 Explore P: 0.2481\n",
      "Episode: 321 Total reward: 371.94555325667 Training loss: 186.2357 Explore P: 0.2378\n",
      "Episode: 322 Total reward: 314.3675118465317 Training loss: 5686.4414 Explore P: 0.2301\n",
      "Episode: 323 Total reward: 329.7785434060783 Training loss: 113.9975 Explore P: 0.2217\n",
      "Episode: 324 Total reward: 325.1154986065964 Training loss: 4427.8613 Explore P: 0.2136\n",
      "Episode: 325 Total reward: 164.23492080256383 Training loss: 5854.1021 Explore P: 0.2092\n",
      "Episode: 326 Total reward: 370.0051552379382 Training loss: 14282.6289 Explore P: 0.2008\n",
      "Episode: 327 Total reward: 338.6851448288417 Training loss: 4920.7690 Explore P: 0.1934\n",
      "Episode: 328 Total reward: 172.91693265927591 Training loss: 357.7671 Explore P: 0.1893\n",
      "Episode: 329 Total reward: 455.5903722454785 Training loss: 12464.7031 Explore P: 0.1806\n",
      "Episode: 330 Total reward: 318.710245225225 Training loss: 875.6934 Explore P: 0.1743\n",
      "Episode: 331 Total reward: 150.15898901772462 Training loss: 580.8823 Explore P: 0.1711\n",
      "Episode: 332 Total reward: 284.2098464082804 Training loss: 688.3420 Explore P: 0.1656\n",
      "Episode: 333 Total reward: 303.1131586496738 Training loss: 154.0401 Explore P: 0.1601\n",
      "Episode: 334 Total reward: 300.4141432131352 Training loss: 612.5991 Explore P: 0.1549\n",
      "Episode: 335 Total reward: 200.33730593206295 Training loss: 509.8601 Explore P: 0.1513\n",
      "Episode: 336 Total reward: 356.91379535248115 Training loss: 19226.6836 Explore P: 0.1455\n",
      "Episode: 337 Total reward: 460.01683514564877 Training loss: 1455.0657 Explore P: 0.1389\n",
      "Episode: 338 Total reward: 232.30613090721965 Training loss: 855.7354 Explore P: 0.1353\n",
      "Episode: 339 Total reward: 465.0278305117502 Training loss: 592.8726 Explore P: 0.1292\n",
      "Episode: 340 Total reward: 259.88197757868596 Training loss: 42484.2031 Explore P: 0.1255\n",
      "Episode: 341 Total reward: 267.51337967404845 Training loss: 409.8819 Explore P: 0.1218\n",
      "Episode: 342 Total reward: 344.51107195061195 Training loss: 1203.5630 Explore P: 0.1174\n",
      "Episode: 343 Total reward: 339.8407907713533 Training loss: 1508.2667 Explore P: 0.1132\n",
      "Episode: 344 Total reward: 232.03607256394326 Training loss: 19483.2871 Explore P: 0.1103\n",
      "Episode: 345 Total reward: 311.1259240808761 Training loss: 67138.7734 Explore P: 0.1067\n",
      "Episode: 346 Total reward: 408.73632648670286 Training loss: 1590.9902 Explore P: 0.1023\n",
      "Episode: 347 Total reward: 221.9054608198128 Training loss: 362.5707 Explore P: 0.0999\n",
      "Episode: 348 Total reward: 373.3380726603512 Training loss: 1508.9265 Explore P: 0.0961\n",
      "Episode: 349 Total reward: 242.13246429934446 Training loss: 3910.1326 Explore P: 0.0936\n",
      "Episode: 350 Total reward: 453.8095974755938 Training loss: 3939.8840 Explore P: 0.0895\n",
      "Episode: 351 Total reward: 230.85218118003922 Training loss: 3207.4978 Explore P: 0.0873\n",
      "Episode: 352 Total reward: 473.81761141871453 Training loss: 2172.1497 Explore P: 0.0835\n",
      "Episode: 353 Total reward: 470.1078280245553 Training loss: 4728.6504 Explore P: 0.0800\n",
      "Episode: 354 Total reward: 407.4957377455345 Training loss: 37183.0820 Explore P: 0.0768\n",
      "Episode: 355 Total reward: 443.3943182560393 Training loss: 4102.4165 Explore P: 0.0736\n",
      "Episode: 356 Total reward: 473.4115667912209 Training loss: 62676.2383 Explore P: 0.0705\n",
      "Episode: 357 Total reward: 322.946040385671 Training loss: 2806.2236 Explore P: 0.0682\n",
      "Episode: 358 Total reward: 464.1742068407816 Training loss: 3677.5967 Explore P: 0.0654\n",
      "Episode: 359 Total reward: 441.3005822376835 Training loss: 6320.6538 Explore P: 0.0627\n",
      "Episode: 360 Total reward: 473.6246429769287 Training loss: 37409.6094 Explore P: 0.0601\n",
      "Episode: 361 Total reward: 380.16714875637854 Training loss: 3774.1636 Explore P: 0.0580\n",
      "Episode: 362 Total reward: 432.05984468710824 Training loss: 6761.7920 Explore P: 0.0557\n",
      "Episode: 363 Total reward: 365.2757223961677 Training loss: 2199.6453 Explore P: 0.0538\n",
      "Episode: 364 Total reward: 473.3291673879146 Training loss: 3900.8845 Explore P: 0.0517\n",
      "Episode: 365 Total reward: 388.61690318991606 Training loss: 220105.0156 Explore P: 0.0499\n",
      "Episode: 366 Total reward: 405.22078555515435 Training loss: 4606.2925 Explore P: 0.0481\n",
      "Episode: 367 Total reward: 449.2686004640014 Training loss: 44479.1328 Explore P: 0.0462\n",
      "Episode: 368 Total reward: 333.1972700061869 Training loss: 230206.1250 Explore P: 0.0449\n",
      "Episode: 369 Total reward: 316.2496641758694 Training loss: 11013.9834 Explore P: 0.0436\n",
      "Episode: 370 Total reward: 350.0520682465117 Training loss: 6008.9937 Explore P: 0.0423\n",
      "Episode: 371 Total reward: 271.41297361255346 Training loss: 3592.4858 Explore P: 0.0413\n",
      "Episode: 372 Total reward: 454.4912529596312 Training loss: 6965.5259 Explore P: 0.0397\n",
      "Episode: 373 Total reward: 462.1877769632213 Training loss: 1961.3044 Explore P: 0.0383\n",
      "Episode: 374 Total reward: 441.2102565392688 Training loss: 12625.4795 Explore P: 0.0369\n",
      "Episode: 375 Total reward: 474.61868351036003 Training loss: 4646.5059 Explore P: 0.0356\n",
      "Episode: 376 Total reward: 402.2060275414711 Training loss: 1519.2246 Explore P: 0.0345\n",
      "Episode: 377 Total reward: 369.7810611643694 Training loss: 8250.7129 Explore P: 0.0335\n",
      "Episode: 378 Total reward: 477.1390916540818 Training loss: 8331.9043 Explore P: 0.0323\n",
      "Episode: 379 Total reward: 355.21390977816077 Training loss: 3379.3931 Explore P: 0.0314\n",
      "Episode: 380 Total reward: 453.64874929918886 Training loss: 57621.4805 Explore P: 0.0304\n",
      "Episode: 381 Total reward: 477.2990165094928 Training loss: 2603.2524 Explore P: 0.0294\n",
      "Episode: 382 Total reward: 451.8771688370535 Training loss: 12417.4883 Explore P: 0.0284\n",
      "Episode: 383 Total reward: 472.37466482666014 Training loss: 21518.1934 Explore P: 0.0275\n",
      "Episode: 384 Total reward: 474.9588784891597 Training loss: 8840.0244 Explore P: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 385 Total reward: 400.8435073447561 Training loss: 13070.3770 Explore P: 0.0260\n",
      "Episode: 386 Total reward: 405.321315355401 Training loss: 7853.6924 Explore P: 0.0252\n",
      "Episode: 387 Total reward: 439.1054180166357 Training loss: 14743.7227 Explore P: 0.0245\n",
      "Episode: 388 Total reward: 451.2559030670337 Training loss: 10276.6426 Explore P: 0.0238\n",
      "Episode: 389 Total reward: 460.14156079358554 Training loss: 11435.9854 Explore P: 0.0231\n",
      "Episode: 390 Total reward: 473.5193981790946 Training loss: 3568.0505 Explore P: 0.0225\n",
      "Episode: 391 Total reward: 474.1305826332901 Training loss: 16355.5137 Explore P: 0.0219\n",
      "Episode: 392 Total reward: 464.9514822495451 Training loss: 9452.6885 Explore P: 0.0213\n",
      "Episode: 393 Total reward: 474.75934514234956 Training loss: 5435.4932 Explore P: 0.0208\n",
      "Episode: 394 Total reward: 474.2633110567766 Training loss: 454325.7500 Explore P: 0.0202\n",
      "Episode: 395 Total reward: 472.6983801628855 Training loss: 13476.2783 Explore P: 0.0197\n",
      "Episode: 396 Total reward: 475.80508621926003 Training loss: 25922.3125 Explore P: 0.0193\n",
      "Episode: 397 Total reward: 475.45346486899746 Training loss: 14193.8291 Explore P: 0.0188\n",
      "Episode: 398 Total reward: 473.8666849146629 Training loss: 37059.0391 Explore P: 0.0184\n",
      "Episode: 399 Total reward: 475.39416230040644 Training loss: 5107.5176 Explore P: 0.0180\n",
      "Episode: 400 Total reward: 477.0790322423731 Training loss: 23911.6758 Explore P: 0.0176\n",
      "Episode: 401 Total reward: 218.3993089513721 Training loss: 9457.7363 Explore P: 0.0174\n",
      "Episode: 402 Total reward: 456.86532771428205 Training loss: 11145.7178 Explore P: 0.0170\n",
      "Episode: 403 Total reward: 470.34051355425134 Training loss: 395357.2188 Explore P: 0.0167\n",
      "Episode: 404 Total reward: 476.76173181660073 Training loss: 30277.9902 Explore P: 0.0164\n",
      "Episode: 405 Total reward: 375.08058224565934 Training loss: 29732.1699 Explore P: 0.0161\n",
      "Episode: 406 Total reward: 408.0686802316766 Training loss: 929781.6875 Explore P: 0.0158\n",
      "Episode: 407 Total reward: 240.30691814277554 Training loss: 11658.7432 Explore P: 0.0156\n",
      "Episode: 408 Total reward: 441.69448484221056 Training loss: 20188.1758 Explore P: 0.0154\n",
      "Episode: 409 Total reward: 461.11403470180255 Training loss: 16531.0508 Explore P: 0.0151\n",
      "Episode: 410 Total reward: 471.9648007433945 Training loss: 18815.1406 Explore P: 0.0149\n",
      "Episode: 411 Total reward: 475.95589427173456 Training loss: 363930.6250 Explore P: 0.0146\n",
      "Episode: 412 Total reward: 455.5520640486161 Training loss: 31214.5371 Explore P: 0.0144\n",
      "Episode: 413 Total reward: 478.2090348520526 Training loss: 19128.6309 Explore P: 0.0142\n",
      "Episode: 414 Total reward: 477.4979475791043 Training loss: 31684.4160 Explore P: 0.0140\n",
      "Episode: 415 Total reward: 456.20901529717634 Training loss: 21163.1172 Explore P: 0.0138\n",
      "Episode: 416 Total reward: 455.69938728350814 Training loss: 113627.5938 Explore P: 0.0136\n",
      "Episode: 417 Total reward: 448.34960542160866 Training loss: 549533.5000 Explore P: 0.0134\n",
      "Episode: 418 Total reward: 477.7830527018513 Training loss: 28892.0703 Explore P: 0.0133\n",
      "Episode: 419 Total reward: 478.20740514320926 Training loss: 12372.0137 Explore P: 0.0131\n",
      "Episode: 420 Total reward: 271.2963072068477 Training loss: 20617.5703 Explore P: 0.0130\n",
      "Episode: 421 Total reward: 473.60086577487886 Training loss: 24981.0234 Explore P: 0.0129\n",
      "Episode: 422 Total reward: 478.30003874170325 Training loss: 54192.6953 Explore P: 0.0127\n",
      "Episode: 423 Total reward: 473.31750271982196 Training loss: 34445.6797 Explore P: 0.0126\n",
      "Episode: 424 Total reward: 381.6127010464244 Training loss: 10107.8516 Explore P: 0.0125\n",
      "Episode: 425 Total reward: 460.0197326128554 Training loss: 25943.8223 Explore P: 0.0124\n",
      "Episode: 426 Total reward: 353.8101918771922 Training loss: 9674.9141 Explore P: 0.0123\n",
      "Episode: 427 Total reward: 478.0618014598859 Training loss: 11846.1055 Explore P: 0.0122\n",
      "Episode: 428 Total reward: 475.26999677265405 Training loss: 6498.5840 Explore P: 0.0120\n",
      "Episode: 429 Total reward: 476.0379057212167 Training loss: 14506.8223 Explore P: 0.0120\n",
      "Episode: 430 Total reward: 292.0374780685278 Training loss: 34936.9258 Explore P: 0.0119\n",
      "Episode: 431 Total reward: 473.0007801749124 Training loss: 28678.3105 Explore P: 0.0118\n",
      "Episode: 432 Total reward: 477.6724065476686 Training loss: 50742.1523 Explore P: 0.0117\n",
      "Episode: 433 Total reward: 478.4792845825798 Training loss: 12867.9863 Explore P: 0.0116\n",
      "Episode: 434 Total reward: 299.606953537704 Training loss: 34331.6875 Explore P: 0.0116\n",
      "Episode: 435 Total reward: 294.72476605059893 Training loss: 20537.0684 Explore P: 0.0115\n",
      "Episode: 436 Total reward: 478.23041116628343 Training loss: 82658.6094 Explore P: 0.0114\n",
      "Episode: 437 Total reward: 475.53686220632864 Training loss: 32101.5625 Explore P: 0.0114\n",
      "Episode: 438 Total reward: 475.54606432956217 Training loss: 57169.3398 Explore P: 0.0113\n",
      "Episode: 439 Total reward: 472.30336107294266 Training loss: 43169.0742 Explore P: 0.0112\n",
      "Episode: 440 Total reward: 474.81900354896845 Training loss: 44854.2422 Explore P: 0.0112\n",
      "Episode: 441 Total reward: 374.9501578586005 Training loss: 82021.9609 Explore P: 0.0111\n",
      "Episode: 442 Total reward: 465.0111309902705 Training loss: 186815.3750 Explore P: 0.0111\n",
      "Episode: 443 Total reward: 474.35015197694725 Training loss: 75772.2969 Explore P: 0.0110\n",
      "Episode: 444 Total reward: 477.2843952525842 Training loss: 67260.6641 Explore P: 0.0110\n",
      "Episode: 445 Total reward: 297.3511907141822 Training loss: 32379.6738 Explore P: 0.0109\n",
      "Episode: 446 Total reward: 476.716128845069 Training loss: 8399.7793 Explore P: 0.0109\n",
      "Episode: 447 Total reward: 475.2084544010032 Training loss: 19797.0234 Explore P: 0.0108\n",
      "Episode: 448 Total reward: 474.24808222586785 Training loss: 59966.6953 Explore P: 0.0108\n",
      "Episode: 449 Total reward: 475.72027417530927 Training loss: 29962.5820 Explore P: 0.0108\n",
      "Episode: 450 Total reward: 469.6762318632836 Training loss: 41709.5664 Explore P: 0.0107\n",
      "Episode: 451 Total reward: 475.38820614420723 Training loss: 35996.9219 Explore P: 0.0107\n",
      "Episode: 452 Total reward: 473.87512923946076 Training loss: 17341.9023 Explore P: 0.0107\n",
      "Episode: 453 Total reward: 476.5056979835802 Training loss: 61832.4414 Explore P: 0.0106\n",
      "Episode: 454 Total reward: 470.4649539030048 Training loss: 19197.8105 Explore P: 0.0106\n",
      "Episode: 455 Total reward: 473.2264918765723 Training loss: 13912.1016 Explore P: 0.0106\n",
      "Episode: 456 Total reward: 456.96468201132797 Training loss: 73569.9141 Explore P: 0.0105\n",
      "Episode: 457 Total reward: 462.89710341502234 Training loss: 83100.4375 Explore P: 0.0105\n",
      "Episode: 458 Total reward: 467.94156465501516 Training loss: 28906.5957 Explore P: 0.0105\n",
      "Episode: 459 Total reward: 476.17976037696604 Training loss: 33677.0508 Explore P: 0.0105\n",
      "Episode: 460 Total reward: 435.4266993299786 Training loss: 45042.5938 Explore P: 0.0104\n",
      "Episode: 461 Total reward: 475.5419778231461 Training loss: 41552.1133 Explore P: 0.0104\n",
      "Episode: 462 Total reward: 259.2194375780235 Training loss: 1861564.2500 Explore P: 0.0104\n",
      "Episode: 463 Total reward: 367.0980559520766 Training loss: 26249.0312 Explore P: 0.0104\n",
      "Episode: 464 Total reward: 477.38753511419725 Training loss: 279631.3750 Explore P: 0.0104\n",
      "Episode: 465 Total reward: 345.62452330096414 Training loss: 48479.7344 Explore P: 0.0104\n",
      "Episode: 466 Total reward: 477.3761259569923 Training loss: 21435.9102 Explore P: 0.0103\n",
      "Episode: 467 Total reward: 369.54751409596093 Training loss: 76729.3594 Explore P: 0.0103\n",
      "Episode: 468 Total reward: 381.57572951139326 Training loss: 48675.7227 Explore P: 0.0103\n",
      "Episode: 469 Total reward: 218.11104339796805 Training loss: 32305.9121 Explore P: 0.0103\n",
      "Episode: 470 Total reward: 253.72323400243775 Training loss: 45138.8438 Explore P: 0.0103\n",
      "Episode: 471 Total reward: 407.2375897583358 Training loss: 28307.2090 Explore P: 0.0103\n",
      "Episode: 472 Total reward: 477.7933524548394 Training loss: 1666760.5000 Explore P: 0.0103\n",
      "Episode: 473 Total reward: 475.0280456849375 Training loss: 50700.4805 Explore P: 0.0103\n",
      "Episode: 474 Total reward: 333.49472981387174 Training loss: 33701.4023 Explore P: 0.0102\n",
      "Episode: 475 Total reward: 477.0058048937956 Training loss: 18634.9570 Explore P: 0.0102\n",
      "Episode: 476 Total reward: 225.82406137028423 Training loss: 39817.9375 Explore P: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 477 Total reward: 477.9682351326731 Training loss: 54095.1641 Explore P: 0.0102\n",
      "Episode: 478 Total reward: 477.2292092391015 Training loss: 34323.6992 Explore P: 0.0102\n",
      "Episode: 479 Total reward: 185.8039641673971 Training loss: 32760.2148 Explore P: 0.0102\n",
      "Episode: 480 Total reward: 476.67466013668724 Training loss: 11990.1943 Explore P: 0.0102\n",
      "Episode: 481 Total reward: 199.03963018073478 Training loss: 27740.0117 Explore P: 0.0102\n",
      "Episode: 482 Total reward: 363.9235089724922 Training loss: 35999.8125 Explore P: 0.0102\n",
      "Episode: 483 Total reward: 309.027897736366 Training loss: 41808.2539 Explore P: 0.0102\n",
      "Episode: 484 Total reward: 477.7811944709701 Training loss: 27083.9414 Explore P: 0.0102\n",
      "Episode: 485 Total reward: 208.64646307924156 Training loss: 27383.1914 Explore P: 0.0102\n",
      "Episode: 486 Total reward: 478.27982160399836 Training loss: 23875.9102 Explore P: 0.0102\n",
      "Episode: 487 Total reward: 399.2902702325731 Training loss: 27072.2617 Explore P: 0.0101\n",
      "Episode: 488 Total reward: 369.5254358570548 Training loss: 1684931.7500 Explore P: 0.0101\n",
      "Episode: 489 Total reward: 332.5100417860518 Training loss: 45807.5938 Explore P: 0.0101\n",
      "Episode: 490 Total reward: 275.9662149403689 Training loss: 23696.3027 Explore P: 0.0101\n",
      "Episode: 491 Total reward: 314.5280757905821 Training loss: 41627.3867 Explore P: 0.0101\n",
      "Episode: 492 Total reward: 478.0334315559891 Training loss: 23831.0586 Explore P: 0.0101\n",
      "Episode: 493 Total reward: 379.82898249236837 Training loss: 8273.1182 Explore P: 0.0101\n",
      "Episode: 494 Total reward: 295.3478389731351 Training loss: 48693.3047 Explore P: 0.0101\n",
      "Episode: 495 Total reward: 355.8618571500468 Training loss: 69963.5312 Explore P: 0.0101\n",
      "Episode: 496 Total reward: 192.92906060025817 Training loss: 27741.2617 Explore P: 0.0101\n",
      "Episode: 497 Total reward: 325.31951168307427 Training loss: 28900.0312 Explore P: 0.0101\n",
      "Episode: 498 Total reward: 395.6476535301786 Training loss: 60248.4609 Explore P: 0.0101\n",
      "Episode: 499 Total reward: 204.25921421109834 Training loss: 45659.1484 Explore P: 0.0101\n",
      "Episode: 500 Total reward: 454.3330885006413 Training loss: 45808.4297 Explore P: 0.0101\n",
      "Episode: 501 Total reward: 221.15536583519423 Training loss: 47582.5312 Explore P: 0.0101\n",
      "Episode: 502 Total reward: 300.4974880674744 Training loss: 39728.0547 Explore P: 0.0101\n",
      "Episode: 503 Total reward: 257.9952318392661 Training loss: 25766.4199 Explore P: 0.0101\n",
      "Episode: 504 Total reward: 238.85875691160192 Training loss: 55456.5547 Explore P: 0.0101\n",
      "Episode: 505 Total reward: 338.80257455489266 Training loss: 80163.8750 Explore P: 0.0101\n",
      "Episode: 506 Total reward: 477.0111361671151 Training loss: 543433.3750 Explore P: 0.0101\n",
      "Episode: 507 Total reward: 163.30428020347787 Training loss: 36326.1992 Explore P: 0.0101\n",
      "Episode: 508 Total reward: 260.3939271146029 Training loss: 18734.7168 Explore P: 0.0101\n",
      "Episode: 509 Total reward: 207.06560863685763 Training loss: 18233.7598 Explore P: 0.0101\n",
      "Episode: 510 Total reward: 353.711802411713 Training loss: 30797.5898 Explore P: 0.0101\n",
      "Episode: 511 Total reward: 278.24149305691225 Training loss: 19571.7734 Explore P: 0.0101\n",
      "Episode: 512 Total reward: 254.48025686406524 Training loss: 17624.8281 Explore P: 0.0101\n",
      "Episode: 513 Total reward: 190.05277135013412 Training loss: 78852.0000 Explore P: 0.0101\n",
      "Episode: 514 Total reward: 250.03508300002517 Training loss: 36346.5039 Explore P: 0.0101\n",
      "Episode: 515 Total reward: 268.42732797100444 Training loss: 17097.0078 Explore P: 0.0101\n",
      "Episode: 516 Total reward: 245.0505135651465 Training loss: 21808.3555 Explore P: 0.0101\n",
      "Episode: 517 Total reward: 257.3121688564731 Training loss: 63905.6836 Explore P: 0.0101\n",
      "Episode: 518 Total reward: 227.74836267644108 Training loss: 36383.3555 Explore P: 0.0100\n",
      "Episode: 519 Total reward: 337.96315544797125 Training loss: 308087.4375 Explore P: 0.0100\n",
      "Episode: 520 Total reward: 366.52450209240396 Training loss: 148772.4375 Explore P: 0.0100\n",
      "Episode: 521 Total reward: 187.20771472440998 Training loss: 23247.6562 Explore P: 0.0100\n",
      "Episode: 522 Total reward: 292.8220634387962 Training loss: 28182.6973 Explore P: 0.0100\n",
      "Episode: 523 Total reward: 445.98064153364453 Training loss: 11710.2246 Explore P: 0.0100\n",
      "Episode: 524 Total reward: 353.33018603171627 Training loss: 72406.1953 Explore P: 0.0100\n",
      "Episode: 525 Total reward: 213.59815984389715 Training loss: 65293.6016 Explore P: 0.0100\n",
      "Episode: 526 Total reward: 314.69074491364876 Training loss: 33704.2031 Explore P: 0.0100\n",
      "Episode: 527 Total reward: 476.66151638487884 Training loss: 1859115.1250 Explore P: 0.0100\n",
      "Episode: 528 Total reward: 182.91017995651157 Training loss: 21139.3828 Explore P: 0.0100\n",
      "Episode: 529 Total reward: 213.51202688223486 Training loss: 27891.5312 Explore P: 0.0100\n",
      "Episode: 530 Total reward: 433.4316754128668 Training loss: 37215.4062 Explore P: 0.0100\n",
      "Episode: 531 Total reward: 409.8668857386311 Training loss: 39764.1328 Explore P: 0.0100\n",
      "Episode: 532 Total reward: 443.38323363760657 Training loss: 34033.4414 Explore P: 0.0100\n",
      "Episode: 533 Total reward: 143.98962116094947 Training loss: 16094.8242 Explore P: 0.0100\n",
      "Episode: 534 Total reward: 211.60533523639774 Training loss: 47770.0938 Explore P: 0.0100\n",
      "Episode: 535 Total reward: 215.25102672231753 Training loss: 41548.1914 Explore P: 0.0100\n",
      "Episode: 536 Total reward: 202.26983099348936 Training loss: 38618.6953 Explore P: 0.0100\n",
      "Episode: 537 Total reward: 320.6195780282731 Training loss: 15032.3096 Explore P: 0.0100\n",
      "Episode: 538 Total reward: 474.8166039729228 Training loss: 31045.6934 Explore P: 0.0100\n",
      "Episode: 539 Total reward: 189.7557797962378 Training loss: 13094.3760 Explore P: 0.0100\n",
      "Episode: 540 Total reward: 306.8957966262222 Training loss: 16161.4971 Explore P: 0.0100\n",
      "Episode: 541 Total reward: 221.87200604098277 Training loss: 38978.0039 Explore P: 0.0100\n",
      "Episode: 542 Total reward: 401.78565967417853 Training loss: 31078.3047 Explore P: 0.0100\n",
      "Episode: 543 Total reward: 184.52889035404925 Training loss: 20908.0469 Explore P: 0.0100\n",
      "Episode: 544 Total reward: 402.92870732081246 Training loss: 19219.8594 Explore P: 0.0100\n",
      "Episode: 545 Total reward: 456.7661955579956 Training loss: 23697.1523 Explore P: 0.0100\n",
      "Episode: 546 Total reward: 425.24855048302476 Training loss: 16149.6465 Explore P: 0.0100\n",
      "Episode: 547 Total reward: 118.5547568420206 Training loss: 13982.3174 Explore P: 0.0100\n",
      "Episode: 548 Total reward: 187.75607425354636 Training loss: 13187.2539 Explore P: 0.0100\n",
      "Episode: 549 Total reward: 193.97290657438649 Training loss: 16407.9453 Explore P: 0.0100\n",
      "Episode: 550 Total reward: 335.6343693466357 Training loss: 34976.3242 Explore P: 0.0100\n",
      "Episode: 551 Total reward: 197.08808223382522 Training loss: 8462.4072 Explore P: 0.0100\n",
      "Episode: 552 Total reward: 253.56332141243126 Training loss: 6358.9946 Explore P: 0.0100\n",
      "Episode: 553 Total reward: 302.7799464167067 Training loss: 18847.8594 Explore P: 0.0100\n",
      "Episode: 554 Total reward: 476.78047562247343 Training loss: 16988.7031 Explore P: 0.0100\n",
      "Episode: 555 Total reward: 182.76232248436676 Training loss: 10748.4551 Explore P: 0.0100\n",
      "Episode: 556 Total reward: 439.0290569005896 Training loss: 12854.2959 Explore P: 0.0100\n",
      "Episode: 557 Total reward: 472.76381635754797 Training loss: 4952497.0000 Explore P: 0.0100\n",
      "Episode: 558 Total reward: 164.430953380683 Training loss: 8772.9258 Explore P: 0.0100\n",
      "Episode: 559 Total reward: 476.60544929821003 Training loss: 12115.4629 Explore P: 0.0100\n",
      "Episode: 560 Total reward: 335.53176638631896 Training loss: 9861.4199 Explore P: 0.0100\n",
      "Episode: 561 Total reward: 476.2760156981323 Training loss: 9103.3418 Explore P: 0.0100\n",
      "Episode: 562 Total reward: 478.2823037564882 Training loss: 13251.2480 Explore P: 0.0100\n",
      "Episode: 563 Total reward: 349.83078945596634 Training loss: 6506.4873 Explore P: 0.0100\n",
      "Episode: 564 Total reward: 445.73277295316296 Training loss: 9257.7334 Explore P: 0.0100\n",
      "Episode: 565 Total reward: 448.1170851373296 Training loss: 6042.1528 Explore P: 0.0100\n",
      "Episode: 566 Total reward: 476.90601865626013 Training loss: 9884.7109 Explore P: 0.0100\n",
      "Episode: 567 Total reward: 226.259552903165 Training loss: 13724.5898 Explore P: 0.0100\n",
      "Episode: 568 Total reward: 245.34985853811784 Training loss: 7025.2744 Explore P: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 569 Total reward: 231.7992181318842 Training loss: 7200.1074 Explore P: 0.0100\n",
      "Episode: 570 Total reward: 477.6735350143897 Training loss: 6098.2539 Explore P: 0.0100\n",
      "Episode: 571 Total reward: 476.9679217394661 Training loss: 5790.0840 Explore P: 0.0100\n",
      "Episode: 572 Total reward: 476.9423062726911 Training loss: 5422.9712 Explore P: 0.0100\n",
      "Episode: 573 Total reward: 475.0112081543152 Training loss: 5431.2520 Explore P: 0.0100\n",
      "Episode: 574 Total reward: 476.3454155723213 Training loss: 7492.0176 Explore P: 0.0100\n",
      "Episode: 575 Total reward: 476.0338987507686 Training loss: 5138.2593 Explore P: 0.0100\n",
      "Episode: 576 Total reward: 476.2923068844093 Training loss: 6019.7236 Explore P: 0.0100\n",
      "Episode: 577 Total reward: 477.4566860293248 Training loss: 3682.1992 Explore P: 0.0100\n",
      "Episode: 578 Total reward: 342.2271697656738 Training loss: 3845.8455 Explore P: 0.0100\n",
      "Episode: 579 Total reward: 476.4911130216206 Training loss: 4698.9521 Explore P: 0.0100\n",
      "Episode: 580 Total reward: 278.20194176622954 Training loss: 7365.8931 Explore P: 0.0100\n",
      "Episode: 581 Total reward: 476.56308394864885 Training loss: 5269.3057 Explore P: 0.0100\n",
      "Episode: 582 Total reward: 346.6103657608627 Training loss: 4105.2271 Explore P: 0.0100\n",
      "Episode: 583 Total reward: 476.62894715510106 Training loss: 3163.1982 Explore P: 0.0100\n",
      "Episode: 584 Total reward: 477.39872244608864 Training loss: 3790.7480 Explore P: 0.0100\n",
      "Episode: 585 Total reward: 476.08638530458813 Training loss: 4893.8716 Explore P: 0.0100\n",
      "Episode: 586 Total reward: 475.2307467244802 Training loss: 5286.3535 Explore P: 0.0100\n",
      "Episode: 587 Total reward: 476.5769360576981 Training loss: 3169.7866 Explore P: 0.0100\n",
      "Episode: 588 Total reward: 477.2223632579629 Training loss: 3455.7834 Explore P: 0.0100\n",
      "Episode: 589 Total reward: 476.9566563077509 Training loss: 4473.5381 Explore P: 0.0100\n",
      "Episode: 590 Total reward: 476.0993409745659 Training loss: 3476.0957 Explore P: 0.0100\n",
      "Episode: 591 Total reward: 478.17681359547095 Training loss: 6765.7769 Explore P: 0.0100\n",
      "Episode: 592 Total reward: 477.27893183680504 Training loss: 9129.7480 Explore P: 0.0100\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment these next 2 lines to watch the training\n",
    "            # env.render() \n",
    "            # sleep(0.0005)\n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # reduce the reward if the cart is not centered\n",
    "            reward = reward * (1 - abs(next_state[1]/2.4))\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        # if the agent gets 10 rewards bigger than 470 consecutively, stop the training\n",
    "        # 499 is never going to be reached because of the penalized reward\n",
    "        if len(rewards_list) > 10:\n",
    "            stop_training = False\n",
    "            for reward in rewards_list[-10:]:\n",
    "                if reward[1] < 470:\n",
    "                    break\n",
    "            else:\n",
    "                stop_training = True\n",
    "            if stop_training:\n",
    "                break\n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total Reward')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch a trained agent\n",
    "Note that the episode ends after 500 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_agent(n_episodes):\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        for episode in range(n_episodes):\n",
    "            state = env.reset()\n",
    "            r = 0\n",
    "            while True:\n",
    "                r += 1\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                env.render()\n",
    "                sleep(0.05)\n",
    "                # comment this if statement to see an endless episode\n",
    "                if done:\n",
    "                    env.close()\n",
    "                    print(f\"reward: {r}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n"
     ]
    }
   ],
   "source": [
    "watch_agent(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
