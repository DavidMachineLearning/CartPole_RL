{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, I'll build a neural network that can learn to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](cart-pole.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions: 2\n",
      "States: Box(4,)\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# environment details\n",
    "print('Number of possible actions:', env.action_space.n)\n",
    "print('States:', env.observation_space)\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    env.render()\n",
    "    sleep(0.15)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. The network's goal is to maximize the reward by keeping the pole vertical.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "The neural network accepts a state $s$ as input and the output will be $Q$-values for each available action $a$.\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "Below is one implementation of the $Q$-network that uses 3 fully connected layers with ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def fully_connected(name, input_tensor, num_units, activation=tf.nn.relu):\n",
    "    \"\"\"Returns a fully connected layer\"\"\"\n",
    "    # initialize weights\n",
    "    w = tf.compat.v1.get_variable(f\"W_{name}\", shape=[input_tensor.get_shape()[1], num_units],\n",
    "                                  initializer=tf.compat.v1.initializers.he_uniform(),\n",
    "                                  dtype=tf.float32, trainable=True)\n",
    "    # initialize bias\n",
    "    b = tf.compat.v1.get_variable(f\"B_{name}\", shape=[num_units], \n",
    "                                  initializer=tf.constant_initializer(0.0), \n",
    "                                  dtype=tf.float32,\n",
    "                                  trainable=True)\n",
    "    # output\n",
    "    out = tf.matmul(input_tensor, w) + b\n",
    "    # add activation\n",
    "    if activation:\n",
    "        out = activation(out, name=f\"activation_{name}\")\n",
    "    # change name\n",
    "    out = tf.compat.v1.identity(out, name=name)\n",
    "\n",
    "    return out\n",
    "    \n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        with tf.variable_scope(name):\n",
    "            # state inputs to the Q-network\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = fully_connected(\"h1\", self.inputs_, hidden_size)\n",
    "            self.fc2 = fully_connected(\"h2\", self.fc1, hidden_size)\n",
    "            self.fc3 = fully_connected(\"h3\", self.fc2, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = fully_connected(\"output\", self.fc3, action_size, activation=None)\n",
    "            \n",
    "            ### Train using mean squared error and Adam gradient descent.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "This `Memory` object will store model's experience $<state, action, reward, next state>$. \n",
    "This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. \n",
    "Then, we'll sample a random mini-batch of transitions $<state, action, reward, next state>$ and train on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 700          # max number of episodes to learn from\n",
    "max_steps = 500               # max steps in an episode\n",
    "gamma = 1.0                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0002            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000            # memory capacity\n",
    "batch_size = 32                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "I re-initialize the simulation and pre-populate the memory in order to use later on the mini-batch.\n",
    "To do this the agent will take random actions and storing the transitions in memory.\n",
    "I also decided to modify the value of the reward in order to get a bigger reward if the cart stays centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    # reduce the reward if the cart is not centered\n",
    "    reward = max(0, reward * (1 - abs(next_state[0]/2.4)))\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now it is time to train the agent.\n",
    "The training will stop automatically after 700 episodes or after 10 consecutive very high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 35.18277752388554 Explore P: 0.9929\n",
      "Episode: 2 Total reward: 12.73632205680921 Explore P: 0.9903\n",
      "Episode: 3 Total reward: 51.641087897731865 Explore P: 0.9800\n",
      "Episode: 4 Total reward: 14.731203736821483 Explore P: 0.9771\n",
      "Episode: 5 Total reward: 14.701136964827645 Explore P: 0.9742\n",
      "Episode: 6 Total reward: 10.735438216420054 Explore P: 0.9721\n",
      "Episode: 7 Total reward: 12.780584546096783 Explore P: 0.9696\n",
      "Episode: 8 Total reward: 16.834109751475253 Explore P: 0.9663\n",
      "Episode: 9 Total reward: 8.59367272208644 Explore P: 0.9646\n",
      "Episode: 10 Total reward: 15.67401448024114 Explore P: 0.9616\n",
      "Episode: 11 Total reward: 15.605994668208064 Explore P: 0.9585\n",
      "Episode: 12 Total reward: 18.239812403759238 Explore P: 0.9549\n",
      "Episode: 13 Total reward: 13.648627406224046 Explore P: 0.9523\n",
      "Episode: 14 Total reward: 9.662084146028208 Explore P: 0.9504\n",
      "Episode: 15 Total reward: 30.52794217278961 Explore P: 0.9446\n",
      "Episode: 16 Total reward: 13.506436587515097 Explore P: 0.9420\n",
      "Episode: 17 Total reward: 30.256540352990797 Explore P: 0.9362\n",
      "Episode: 18 Total reward: 17.377407040643124 Explore P: 0.9329\n",
      "Episode: 19 Total reward: 11.819030800081297 Explore P: 0.9307\n",
      "Episode: 20 Total reward: 15.451942230868916 Explore P: 0.9277\n",
      "Episode: 21 Total reward: 12.837332651059244 Explore P: 0.9253\n",
      "Episode: 22 Total reward: 17.663628660779263 Explore P: 0.9221\n",
      "Episode: 23 Total reward: 11.69595779949295 Explore P: 0.9199\n",
      "Episode: 24 Total reward: 37.79429433292033 Explore P: 0.9128\n",
      "Episode: 25 Total reward: 16.721683009325922 Explore P: 0.9097\n",
      "Episode: 26 Total reward: 12.774716697162889 Explore P: 0.9074\n",
      "Episode: 27 Total reward: 10.691654403115434 Explore P: 0.9054\n",
      "Episode: 28 Total reward: 14.471257840914578 Explore P: 0.9027\n",
      "Episode: 29 Total reward: 18.426341419231 Explore P: 0.8994\n",
      "Episode: 30 Total reward: 10.84992781241228 Explore P: 0.8974\n",
      "Episode: 31 Total reward: 10.80477353900557 Explore P: 0.8955\n",
      "Episode: 32 Total reward: 16.543048258520084 Explore P: 0.8925\n",
      "Episode: 33 Total reward: 9.644571227378247 Explore P: 0.8907\n",
      "Episode: 34 Total reward: 14.783676659694128 Explore P: 0.8881\n",
      "Episode: 35 Total reward: 9.74209843135483 Explore P: 0.8863\n",
      "Episode: 36 Total reward: 13.665841161345082 Explore P: 0.8838\n",
      "Episode: 37 Total reward: 23.160096995861476 Explore P: 0.8797\n",
      "Episode: 38 Total reward: 11.590399742752101 Explore P: 0.8776\n",
      "Episode: 39 Total reward: 15.56321055917645 Explore P: 0.8748\n",
      "Episode: 40 Total reward: 11.764742172413904 Explore P: 0.8727\n",
      "Episode: 41 Total reward: 19.80562529257115 Explore P: 0.8693\n",
      "Episode: 42 Total reward: 19.079403465212383 Explore P: 0.8659\n",
      "Episode: 43 Total reward: 16.359827735929077 Explore P: 0.8630\n",
      "Episode: 44 Total reward: 16.52023972050675 Explore P: 0.8601\n",
      "Episode: 45 Total reward: 18.838634661110174 Explore P: 0.8568\n",
      "Episode: 46 Total reward: 9.855394154296357 Explore P: 0.8551\n",
      "Episode: 47 Total reward: 9.61332964025831 Explore P: 0.8535\n",
      "Episode: 48 Total reward: 21.558260205258648 Explore P: 0.8498\n",
      "Episode: 49 Total reward: 12.442815373600972 Explore P: 0.8476\n",
      "Episode: 50 Total reward: 22.785613824083526 Explore P: 0.8436\n",
      "Episode: 51 Total reward: 12.888434694736945 Explore P: 0.8414\n",
      "Episode: 52 Total reward: 22.529598886054 Explore P: 0.8376\n",
      "Episode: 53 Total reward: 24.472724157492365 Explore P: 0.8335\n",
      "Episode: 54 Total reward: 11.664052852709005 Explore P: 0.8315\n",
      "Episode: 55 Total reward: 18.793509509084725 Explore P: 0.8284\n",
      "Episode: 56 Total reward: 17.60786080686929 Explore P: 0.8254\n",
      "Episode: 57 Total reward: 9.854452356147954 Explore P: 0.8238\n",
      "Episode: 58 Total reward: 9.845339131233048 Explore P: 0.8222\n",
      "Episode: 59 Total reward: 10.415752113528285 Explore P: 0.8204\n",
      "Episode: 60 Total reward: 24.398215368363363 Explore P: 0.8163\n",
      "Episode: 61 Total reward: 12.399139092706738 Explore P: 0.8142\n",
      "Episode: 62 Total reward: 14.722405720626888 Explore P: 0.8118\n",
      "Episode: 63 Total reward: 15.663657069112631 Explore P: 0.8093\n",
      "Episode: 64 Total reward: 7.861546147882489 Explore P: 0.8080\n",
      "Episode: 65 Total reward: 12.687930433283963 Explore P: 0.8059\n",
      "Episode: 66 Total reward: 40.0344413450522 Explore P: 0.7993\n",
      "Episode: 67 Total reward: 15.504783325468473 Explore P: 0.7967\n",
      "Episode: 68 Total reward: 11.748319228910725 Explore P: 0.7949\n",
      "Episode: 69 Total reward: 10.540178281951915 Explore P: 0.7931\n",
      "Episode: 70 Total reward: 19.383121666758324 Explore P: 0.7900\n",
      "Episode: 71 Total reward: 12.663000162254612 Explore P: 0.7880\n",
      "Episode: 72 Total reward: 10.77406785529237 Explore P: 0.7863\n",
      "Episode: 73 Total reward: 18.321773810144236 Explore P: 0.7833\n",
      "Episode: 74 Total reward: 25.378266209083097 Explore P: 0.7793\n",
      "Episode: 75 Total reward: 13.703328356850225 Explore P: 0.7772\n",
      "Episode: 76 Total reward: 13.742558881291261 Explore P: 0.7750\n",
      "Episode: 77 Total reward: 20.776464896179647 Explore P: 0.7718\n",
      "Episode: 78 Total reward: 11.637173884859816 Explore P: 0.7700\n",
      "Episode: 79 Total reward: 18.524236924467832 Explore P: 0.7671\n",
      "Episode: 80 Total reward: 11.480501694669206 Explore P: 0.7653\n",
      "Episode: 81 Total reward: 10.678628527114972 Explore P: 0.7636\n",
      "Episode: 82 Total reward: 9.81446959047045 Explore P: 0.7621\n",
      "Episode: 83 Total reward: 14.456644697820458 Explore P: 0.7599\n",
      "Episode: 84 Total reward: 17.509990333972787 Explore P: 0.7572\n",
      "Episode: 85 Total reward: 10.802799803348869 Explore P: 0.7555\n",
      "Episode: 86 Total reward: 20.367051753027706 Explore P: 0.7524\n",
      "Episode: 87 Total reward: 28.57558805558857 Explore P: 0.7481\n",
      "Episode: 88 Total reward: 8.78973353280725 Explore P: 0.7468\n",
      "Episode: 89 Total reward: 11.609459470288673 Explore P: 0.7450\n",
      "Episode: 90 Total reward: 23.75160925255796 Explore P: 0.7415\n",
      "Episode: 91 Total reward: 9.834879615576467 Explore P: 0.7400\n",
      "Episode: 92 Total reward: 38.76177033161531 Explore P: 0.7341\n",
      "Episode: 93 Total reward: 21.56920242939177 Explore P: 0.7309\n",
      "Episode: 94 Total reward: 9.781383283007926 Explore P: 0.7295\n",
      "Episode: 95 Total reward: 18.633288033790187 Explore P: 0.7267\n",
      "Episode: 96 Total reward: 12.444758615570912 Explore P: 0.7249\n",
      "Episode: 97 Total reward: 17.754793906101398 Explore P: 0.7223\n",
      "Episode: 98 Total reward: 13.54462487560697 Explore P: 0.7203\n",
      "Episode: 99 Total reward: 31.318598898188213 Explore P: 0.7158\n",
      "Episode: 100 Total reward: 19.88460208069335 Explore P: 0.7130\n",
      "Episode: 101 Total reward: 18.7190418161894 Explore P: 0.7103\n",
      "Episode: 102 Total reward: 7.862024253026678 Explore P: 0.7092\n",
      "Episode: 103 Total reward: 17.679763318972544 Explore P: 0.7067\n",
      "Episode: 104 Total reward: 12.800985700120423 Explore P: 0.7049\n",
      "Episode: 105 Total reward: 42.96299921463245 Explore P: 0.6986\n",
      "Episode: 106 Total reward: 15.658576831712669 Explore P: 0.6964\n",
      "Episode: 107 Total reward: 14.281409408580531 Explore P: 0.6944\n",
      "Episode: 108 Total reward: 10.62934354203632 Explore P: 0.6929\n",
      "Episode: 109 Total reward: 11.807894737586832 Explore P: 0.6912\n",
      "Episode: 110 Total reward: 14.838469613708906 Explore P: 0.6892\n",
      "Episode: 111 Total reward: 7.711023577006462 Explore P: 0.6881\n",
      "Episode: 112 Total reward: 12.625072095795359 Explore P: 0.6863\n",
      "Episode: 113 Total reward: 9.68743686702213 Explore P: 0.6850\n",
      "Episode: 114 Total reward: 35.01733625237477 Explore P: 0.6802\n",
      "Episode: 115 Total reward: 7.858123835854129 Explore P: 0.6791\n",
      "Episode: 116 Total reward: 19.299727412732164 Explore P: 0.6764\n",
      "Episode: 117 Total reward: 13.398726530105234 Explore P: 0.6745\n",
      "Episode: 118 Total reward: 9.537709013954347 Explore P: 0.6732\n",
      "Episode: 119 Total reward: 6.799270847645952 Explore P: 0.6723\n",
      "Episode: 120 Total reward: 19.54655131776003 Explore P: 0.6696\n",
      "Episode: 121 Total reward: 13.748098145728646 Explore P: 0.6678\n",
      "Episode: 122 Total reward: 23.342306269505382 Explore P: 0.6647\n",
      "Episode: 123 Total reward: 10.693874480715808 Explore P: 0.6632\n",
      "Episode: 124 Total reward: 16.39097797128373 Explore P: 0.6610\n",
      "Episode: 125 Total reward: 10.455500307385389 Explore P: 0.6596\n",
      "Episode: 126 Total reward: 12.730018395777147 Explore P: 0.6579\n",
      "Episode: 127 Total reward: 27.12222576155499 Explore P: 0.6543\n",
      "Episode: 128 Total reward: 12.447970594582415 Explore P: 0.6526\n",
      "Episode: 129 Total reward: 37.596491008709485 Explore P: 0.6477\n",
      "Episode: 130 Total reward: 7.88206613775332 Explore P: 0.6467\n",
      "Episode: 131 Total reward: 14.709816691770314 Explore P: 0.6448\n",
      "Episode: 132 Total reward: 7.763152221939052 Explore P: 0.6438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 133 Total reward: 7.795766097967892 Explore P: 0.6428\n",
      "Episode: 134 Total reward: 21.50302200218647 Explore P: 0.6400\n",
      "Episode: 135 Total reward: 15.553197060513574 Explore P: 0.6380\n",
      "Episode: 136 Total reward: 18.695636072124916 Explore P: 0.6356\n",
      "Episode: 137 Total reward: 18.18542399829996 Explore P: 0.6332\n",
      "Episode: 138 Total reward: 15.516109513582908 Explore P: 0.6312\n",
      "Episode: 139 Total reward: 14.820056633355398 Explore P: 0.6294\n",
      "Episode: 140 Total reward: 20.77931943323815 Explore P: 0.6268\n",
      "Episode: 141 Total reward: 18.526563868852293 Explore P: 0.6244\n",
      "Episode: 142 Total reward: 7.89298805518739 Explore P: 0.6235\n",
      "Episode: 143 Total reward: 21.610402988977054 Explore P: 0.6208\n",
      "Episode: 144 Total reward: 10.535298331759055 Explore P: 0.6194\n",
      "Episode: 145 Total reward: 10.783019119058176 Explore P: 0.6181\n",
      "Episode: 146 Total reward: 13.436477789935404 Explore P: 0.6164\n",
      "Episode: 147 Total reward: 35.6378375894387 Explore P: 0.6119\n",
      "Episode: 148 Total reward: 30.543215437114743 Explore P: 0.6081\n",
      "Episode: 149 Total reward: 16.64238895238054 Explore P: 0.6060\n",
      "Episode: 150 Total reward: 11.881869448549088 Explore P: 0.6046\n",
      "Episode: 151 Total reward: 22.318631648583022 Explore P: 0.6019\n",
      "Episode: 152 Total reward: 14.627188873173553 Explore P: 0.6001\n",
      "Episode: 153 Total reward: 48.877826559031476 Explore P: 0.5940\n",
      "Episode: 154 Total reward: 10.779267413947933 Explore P: 0.5927\n",
      "Episode: 155 Total reward: 19.493124544618293 Explore P: 0.5904\n",
      "Episode: 156 Total reward: 12.810942309734841 Explore P: 0.5889\n",
      "Episode: 157 Total reward: 9.577347397956615 Explore P: 0.5877\n",
      "Episode: 158 Total reward: 25.54560328951092 Explore P: 0.5847\n",
      "Episode: 159 Total reward: 37.49882609915293 Explore P: 0.5803\n",
      "Episode: 160 Total reward: 10.800147957155724 Explore P: 0.5790\n",
      "Episode: 161 Total reward: 8.745110653864874 Explore P: 0.5780\n",
      "Episode: 162 Total reward: 21.52523507508881 Explore P: 0.5755\n",
      "Episode: 163 Total reward: 57.58975239686799 Explore P: 0.5688\n",
      "Episode: 164 Total reward: 8.831065893460885 Explore P: 0.5677\n",
      "Episode: 165 Total reward: 23.688361097018554 Explore P: 0.5651\n",
      "Episode: 166 Total reward: 40.84035303425587 Explore P: 0.5604\n",
      "Episode: 167 Total reward: 63.15988994634622 Explore P: 0.5533\n",
      "Episode: 168 Total reward: 96.39344353495049 Explore P: 0.5427\n",
      "Episode: 169 Total reward: 24.696303406435106 Explore P: 0.5400\n",
      "Episode: 170 Total reward: 87.01098127714454 Explore P: 0.5308\n",
      "Episode: 171 Total reward: 36.357647350739285 Explore P: 0.5269\n",
      "Episode: 172 Total reward: 68.16458503705768 Explore P: 0.5196\n",
      "Episode: 173 Total reward: 83.41271857319545 Explore P: 0.5110\n",
      "Episode: 174 Total reward: 49.94071360657339 Explore P: 0.5060\n",
      "Episode: 175 Total reward: 69.25520767990895 Explore P: 0.4986\n",
      "Episode: 176 Total reward: 21.01856649080849 Explore P: 0.4964\n",
      "Episode: 177 Total reward: 102.67884394067256 Explore P: 0.4853\n",
      "Episode: 178 Total reward: 29.35318564525468 Explore P: 0.4824\n",
      "Episode: 179 Total reward: 67.69039942370479 Explore P: 0.4757\n",
      "Episode: 180 Total reward: 117.21015400752103 Explore P: 0.4635\n",
      "Episode: 181 Total reward: 65.74330742208056 Explore P: 0.4574\n",
      "Episode: 182 Total reward: 79.74942318027007 Explore P: 0.4501\n",
      "Episode: 183 Total reward: 126.86185501023675 Explore P: 0.4388\n",
      "Episode: 184 Total reward: 102.31430046328938 Explore P: 0.4293\n",
      "Episode: 185 Total reward: 45.52995341678053 Explore P: 0.4253\n",
      "Episode: 186 Total reward: 18.6688414863233 Explore P: 0.4237\n",
      "Episode: 187 Total reward: 75.81304730832943 Explore P: 0.4170\n",
      "Episode: 188 Total reward: 63.24803475713658 Explore P: 0.4116\n",
      "Episode: 189 Total reward: 220.5193086076062 Explore P: 0.3939\n",
      "Episode: 190 Total reward: 64.70667518063325 Explore P: 0.3884\n",
      "Episode: 191 Total reward: 87.53354937241357 Explore P: 0.3811\n",
      "Episode: 192 Total reward: 225.81453673449008 Explore P: 0.3612\n",
      "Episode: 193 Total reward: 152.47050849761965 Explore P: 0.3480\n",
      "Episode: 194 Total reward: 79.10500572195826 Explore P: 0.3420\n",
      "Episode: 195 Total reward: 53.365257975851165 Explore P: 0.3382\n",
      "Episode: 196 Total reward: 71.31240287197114 Explore P: 0.3333\n",
      "Episode: 197 Total reward: 83.71186697864869 Explore P: 0.3276\n",
      "Episode: 198 Total reward: 38.73569978789933 Explore P: 0.3252\n",
      "Episode: 199 Total reward: 102.21139655622441 Explore P: 0.3182\n",
      "Episode: 200 Total reward: 102.47026317086477 Explore P: 0.3111\n",
      "Episode: 201 Total reward: 107.53724691734345 Explore P: 0.3039\n",
      "Episode: 202 Total reward: 85.6947417443582 Explore P: 0.2983\n",
      "Episode: 203 Total reward: 63.26304839169664 Explore P: 0.2943\n",
      "Episode: 204 Total reward: 109.77711988113327 Explore P: 0.2874\n",
      "Episode: 205 Total reward: 126.37229722420936 Explore P: 0.2797\n",
      "Episode: 206 Total reward: 100.20739561175225 Explore P: 0.2738\n",
      "Episode: 207 Total reward: 85.9083306156191 Explore P: 0.2685\n",
      "Episode: 208 Total reward: 84.47400569650394 Explore P: 0.2634\n",
      "Episode: 209 Total reward: 94.22008670099059 Explore P: 0.2582\n",
      "Episode: 210 Total reward: 149.83514030008902 Explore P: 0.2500\n",
      "Episode: 211 Total reward: 176.11399599813424 Explore P: 0.2409\n",
      "Episode: 212 Total reward: 104.70740197618316 Explore P: 0.2352\n",
      "Episode: 213 Total reward: 105.76371174296268 Explore P: 0.2298\n",
      "Episode: 214 Total reward: 127.76332494144569 Explore P: 0.2231\n",
      "Episode: 215 Total reward: 159.9839003736762 Explore P: 0.2154\n",
      "Episode: 216 Total reward: 99.41209245208985 Explore P: 0.2104\n",
      "Episode: 217 Total reward: 189.84853620174954 Explore P: 0.2019\n",
      "Episode: 218 Total reward: 139.00338279379218 Explore P: 0.1959\n",
      "Episode: 219 Total reward: 96.41955495211518 Explore P: 0.1917\n",
      "Episode: 220 Total reward: 121.64182268881281 Explore P: 0.1865\n",
      "Episode: 221 Total reward: 87.02231318295217 Explore P: 0.1827\n",
      "Episode: 222 Total reward: 104.37177581942139 Explore P: 0.1783\n",
      "Episode: 223 Total reward: 390.8300975015699 Explore P: 0.1644\n",
      "Episode: 224 Total reward: 139.77678667013245 Explore P: 0.1591\n",
      "Episode: 225 Total reward: 57.892045508563974 Explore P: 0.1574\n",
      "Episode: 226 Total reward: 161.29956470144938 Explore P: 0.1521\n",
      "Episode: 227 Total reward: 278.02487601895837 Explore P: 0.1438\n",
      "Episode: 228 Total reward: 428.2043130265172 Explore P: 0.1319\n",
      "Episode: 229 Total reward: 114.43834119861965 Explore P: 0.1284\n",
      "Episode: 230 Total reward: 200.8890142975665 Explore P: 0.1230\n",
      "Episode: 231 Total reward: 198.94936166741627 Explore P: 0.1180\n",
      "Episode: 232 Total reward: 135.0065791925829 Explore P: 0.1145\n",
      "Episode: 233 Total reward: 166.6148145619882 Explore P: 0.1102\n",
      "Episode: 234 Total reward: 92.45070770921345 Explore P: 0.1080\n",
      "Episode: 235 Total reward: 138.70767368838796 Explore P: 0.1049\n",
      "Episode: 236 Total reward: 131.48326335818365 Explore P: 0.1020\n",
      "Episode: 237 Total reward: 102.75436944441289 Explore P: 0.0998\n",
      "Episode: 238 Total reward: 100.03712164282283 Explore P: 0.0976\n",
      "Episode: 239 Total reward: 120.73652333440185 Explore P: 0.0951\n",
      "Episode: 240 Total reward: 124.47730125002138 Explore P: 0.0927\n",
      "Episode: 241 Total reward: 90.79577546093182 Explore P: 0.0910\n",
      "Episode: 242 Total reward: 194.15825998262 Explore P: 0.0876\n",
      "Episode: 243 Total reward: 174.0170147452887 Explore P: 0.0841\n",
      "Episode: 244 Total reward: 329.2780065710307 Explore P: 0.0785\n",
      "Episode: 245 Total reward: 114.22292882203152 Explore P: 0.0767\n",
      "Episode: 246 Total reward: 165.53753536350678 Explore P: 0.0738\n",
      "Episode: 247 Total reward: 193.64831912172863 Explore P: 0.0706\n",
      "Episode: 248 Total reward: 203.6592690931144 Explore P: 0.0675\n",
      "Episode: 249 Total reward: 150.78571323797735 Explore P: 0.0655\n",
      "Episode: 250 Total reward: 102.55403198906953 Explore P: 0.0642\n",
      "Episode: 251 Total reward: 109.3767842265297 Explore P: 0.0628\n",
      "Episode: 252 Total reward: 480.5713545345343 Explore P: 0.0578\n",
      "Episode: 253 Total reward: 472.7779979420814 Explore P: 0.0532\n",
      "Episode: 254 Total reward: 123.58375310629141 Explore P: 0.0520\n",
      "Episode: 255 Total reward: 193.69406015687517 Explore P: 0.0499\n",
      "Episode: 256 Total reward: 407.28366311633005 Explore P: 0.0465\n",
      "Episode: 257 Total reward: 220.9792257235719 Explore P: 0.0447\n",
      "Episode: 258 Total reward: 493.8756200841336 Explore P: 0.0414\n",
      "Episode: 259 Total reward: 163.47476290377335 Explore P: 0.0401\n",
      "Episode: 260 Total reward: 162.73272098748868 Explore P: 0.0389\n",
      "Episode: 261 Total reward: 188.13039354855624 Explore P: 0.0375\n",
      "Episode: 262 Total reward: 264.06541444729095 Explore P: 0.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 263 Total reward: 185.3256654505144 Explore P: 0.0346\n",
      "Episode: 264 Total reward: 298.2415584548886 Explore P: 0.0330\n",
      "Episode: 265 Total reward: 220.00654064232273 Explore P: 0.0318\n",
      "Episode: 266 Total reward: 127.82373160896866 Explore P: 0.0311\n",
      "Episode: 267 Total reward: 455.74854989455235 Explore P: 0.0291\n",
      "Episode: 268 Total reward: 99.58094591231892 Explore P: 0.0286\n",
      "Episode: 269 Total reward: 462.8658762361165 Explore P: 0.0268\n",
      "Episode: 270 Total reward: 277.2028808303332 Explore P: 0.0258\n",
      "Episode: 271 Total reward: 350.9312670734657 Explore P: 0.0245\n",
      "Episode: 272 Total reward: 481.1611013157279 Explore P: 0.0231\n",
      "Episode: 273 Total reward: 489.2354685575949 Explore P: 0.0219\n",
      "Episode: 274 Total reward: 162.52214954882544 Explore P: 0.0214\n",
      "Episode: 275 Total reward: 430.34160823140473 Explore P: 0.0204\n",
      "Episode: 276 Total reward: 355.4836053062158 Explore P: 0.0196\n",
      "Episode: 277 Total reward: 193.26140146649297 Explore P: 0.0191\n",
      "Episode: 278 Total reward: 155.64103895431532 Explore P: 0.0188\n",
      "Episode: 279 Total reward: 217.87564254879112 Explore P: 0.0183\n",
      "Episode: 280 Total reward: 188.86137891089984 Explore P: 0.0179\n",
      "Episode: 281 Total reward: 496.91251787621854 Explore P: 0.0172\n",
      "Episode: 282 Total reward: 274.00817697855325 Explore P: 0.0167\n",
      "Episode: 283 Total reward: 385.0278097252195 Explore P: 0.0162\n",
      "Episode: 284 Total reward: 334.8338441053331 Explore P: 0.0157\n",
      "Episode: 285 Total reward: 138.3846539452766 Explore P: 0.0155\n",
      "Episode: 286 Total reward: 164.55069167797353 Explore P: 0.0153\n",
      "Episode: 287 Total reward: 273.21944594816716 Explore P: 0.0150\n",
      "Episode: 288 Total reward: 152.9276012121308 Explore P: 0.0148\n",
      "Episode: 289 Total reward: 168.38281709391663 Explore P: 0.0146\n",
      "Episode: 290 Total reward: 361.87647819692745 Explore P: 0.0142\n",
      "Episode: 291 Total reward: 379.32637696337247 Explore P: 0.0139\n",
      "Episode: 292 Total reward: 145.4048813805038 Explore P: 0.0138\n",
      "Episode: 293 Total reward: 252.06800446995595 Explore P: 0.0135\n",
      "Episode: 294 Total reward: 141.8874192256473 Explore P: 0.0134\n",
      "Episode: 295 Total reward: 258.27567075732776 Explore P: 0.0132\n",
      "Episode: 296 Total reward: 481.6820041446867 Explore P: 0.0129\n",
      "Episode: 297 Total reward: 153.9393839469911 Explore P: 0.0128\n",
      "Episode: 298 Total reward: 324.78054349821565 Explore P: 0.0126\n",
      "Episode: 299 Total reward: 272.51802867850165 Explore P: 0.0124\n",
      "Episode: 300 Total reward: 312.6475661190919 Explore P: 0.0123\n",
      "Episode: 301 Total reward: 139.8863466476407 Explore P: 0.0122\n",
      "Episode: 302 Total reward: 194.20787776081602 Explore P: 0.0121\n",
      "Episode: 303 Total reward: 487.4499185017218 Explore P: 0.0119\n",
      "Episode: 304 Total reward: 168.56208374724432 Explore P: 0.0118\n",
      "Episode: 305 Total reward: 184.7863174714374 Explore P: 0.0117\n",
      "Episode: 306 Total reward: 250.021037378054 Explore P: 0.0116\n",
      "Episode: 307 Total reward: 322.12771579717037 Explore P: 0.0115\n",
      "Episode: 308 Total reward: 281.38976658905125 Explore P: 0.0114\n",
      "Episode: 309 Total reward: 202.77964697427373 Explore P: 0.0114\n",
      "Episode: 310 Total reward: 479.1452051441481 Explore P: 0.0112\n",
      "Episode: 311 Total reward: 130.39064140838556 Explore P: 0.0112\n",
      "Episode: 312 Total reward: 190.80040087741065 Explore P: 0.0111\n",
      "Episode: 313 Total reward: 158.59803749111546 Explore P: 0.0111\n",
      "Episode: 314 Total reward: 152.3464116052302 Explore P: 0.0111\n",
      "Episode: 315 Total reward: 484.222737376911 Explore P: 0.0110\n",
      "Episode: 316 Total reward: 177.13292936175253 Explore P: 0.0109\n",
      "Episode: 317 Total reward: 480.0427806860331 Explore P: 0.0108\n",
      "Episode: 318 Total reward: 240.4606440370868 Explore P: 0.0108\n",
      "Episode: 319 Total reward: 170.30629066705137 Explore P: 0.0107\n",
      "Episode: 320 Total reward: 149.35340445940105 Explore P: 0.0107\n",
      "Episode: 321 Total reward: 155.37958004690424 Explore P: 0.0107\n",
      "Episode: 322 Total reward: 495.0085039390836 Explore P: 0.0106\n",
      "Episode: 323 Total reward: 141.58376253239834 Explore P: 0.0106\n",
      "Episode: 324 Total reward: 175.5328416208017 Explore P: 0.0106\n",
      "Episode: 325 Total reward: 185.0235631286097 Explore P: 0.0106\n",
      "Episode: 326 Total reward: 164.73532936051 Explore P: 0.0105\n",
      "Episode: 327 Total reward: 192.31525724999258 Explore P: 0.0105\n",
      "Episode: 328 Total reward: 241.07819942270086 Explore P: 0.0105\n",
      "Episode: 329 Total reward: 320.8693847105205 Explore P: 0.0104\n",
      "Episode: 330 Total reward: 148.87861996812245 Explore P: 0.0104\n",
      "Episode: 331 Total reward: 344.7135784640388 Explore P: 0.0104\n",
      "Episode: 332 Total reward: 296.59599875066715 Explore P: 0.0104\n",
      "Episode: 333 Total reward: 182.64525393284703 Explore P: 0.0104\n",
      "Episode: 334 Total reward: 223.91154677499728 Explore P: 0.0103\n",
      "Episode: 335 Total reward: 205.19779702942006 Explore P: 0.0103\n",
      "Episode: 336 Total reward: 171.16579543162212 Explore P: 0.0103\n",
      "Episode: 337 Total reward: 241.94318774806953 Explore P: 0.0103\n",
      "Episode: 338 Total reward: 179.87895548474694 Explore P: 0.0103\n",
      "Episode: 339 Total reward: 244.17040953992455 Explore P: 0.0103\n",
      "Episode: 340 Total reward: 364.5009564279909 Explore P: 0.0102\n",
      "Episode: 341 Total reward: 147.4424555102141 Explore P: 0.0102\n",
      "Episode: 342 Total reward: 151.01395060985823 Explore P: 0.0102\n",
      "Episode: 343 Total reward: 129.79339318432312 Explore P: 0.0102\n",
      "Episode: 344 Total reward: 238.65687788733382 Explore P: 0.0102\n",
      "Episode: 345 Total reward: 243.06486681105008 Explore P: 0.0102\n",
      "Episode: 346 Total reward: 197.89554704692694 Explore P: 0.0102\n",
      "Episode: 347 Total reward: 184.96061868677938 Explore P: 0.0102\n",
      "Episode: 348 Total reward: 291.6878064765547 Explore P: 0.0102\n",
      "Episode: 349 Total reward: 185.37467830842937 Explore P: 0.0102\n",
      "Episode: 350 Total reward: 220.71472510507417 Explore P: 0.0101\n",
      "Episode: 351 Total reward: 231.7470994767756 Explore P: 0.0101\n",
      "Episode: 352 Total reward: 181.00943055941022 Explore P: 0.0101\n",
      "Episode: 353 Total reward: 155.24604187871452 Explore P: 0.0101\n",
      "Episode: 354 Total reward: 208.1400408129747 Explore P: 0.0101\n",
      "Episode: 355 Total reward: 340.92105055250175 Explore P: 0.0101\n",
      "Episode: 356 Total reward: 219.40083458749507 Explore P: 0.0101\n",
      "Episode: 357 Total reward: 181.26840766904786 Explore P: 0.0101\n",
      "Episode: 358 Total reward: 346.9164218849567 Explore P: 0.0101\n",
      "Episode: 359 Total reward: 239.37000460258108 Explore P: 0.0101\n",
      "Episode: 360 Total reward: 377.3331485392684 Explore P: 0.0101\n",
      "Episode: 361 Total reward: 261.3200332207145 Explore P: 0.0101\n",
      "Episode: 362 Total reward: 221.95823490853732 Explore P: 0.0101\n",
      "Episode: 363 Total reward: 452.9037232732278 Explore P: 0.0101\n",
      "Episode: 364 Total reward: 176.55403938506532 Explore P: 0.0101\n",
      "Episode: 365 Total reward: 207.23253844697678 Explore P: 0.0101\n",
      "Episode: 366 Total reward: 297.48429492938993 Explore P: 0.0101\n",
      "Episode: 367 Total reward: 213.28625286601283 Explore P: 0.0100\n",
      "Episode: 368 Total reward: 175.18795880109204 Explore P: 0.0100\n",
      "Episode: 369 Total reward: 175.93398792860944 Explore P: 0.0100\n",
      "Episode: 370 Total reward: 199.85243400314522 Explore P: 0.0100\n",
      "Episode: 371 Total reward: 201.1123383661616 Explore P: 0.0100\n",
      "Episode: 372 Total reward: 313.76941909627703 Explore P: 0.0100\n",
      "Episode: 373 Total reward: 410.41522196683735 Explore P: 0.0100\n",
      "Episode: 374 Total reward: 485.4923274633342 Explore P: 0.0100\n",
      "Episode: 375 Total reward: 478.48520807570634 Explore P: 0.0100\n",
      "Episode: 376 Total reward: 429.71450563238136 Explore P: 0.0100\n",
      "Episode: 377 Total reward: 185.93655102962975 Explore P: 0.0100\n",
      "Episode: 378 Total reward: 288.38501527343016 Explore P: 0.0100\n",
      "Episode: 379 Total reward: 297.3845947456523 Explore P: 0.0100\n",
      "Episode: 380 Total reward: 199.18280901477598 Explore P: 0.0100\n",
      "Episode: 381 Total reward: 341.6400917509566 Explore P: 0.0100\n",
      "Episode: 382 Total reward: 315.31355239329565 Explore P: 0.0100\n",
      "Episode: 383 Total reward: 254.78949053214507 Explore P: 0.0100\n",
      "Episode: 384 Total reward: 201.46716837720302 Explore P: 0.0100\n",
      "Episode: 385 Total reward: 470.4724121480108 Explore P: 0.0100\n",
      "Episode: 386 Total reward: 233.4334399419161 Explore P: 0.0100\n",
      "Episode: 387 Total reward: 302.76182026557177 Explore P: 0.0100\n",
      "Episode: 388 Total reward: 280.30790281468046 Explore P: 0.0100\n",
      "Episode: 389 Total reward: 460.31955435846146 Explore P: 0.0100\n",
      "Episode: 390 Total reward: 469.50618544907405 Explore P: 0.0100\n",
      "Episode: 391 Total reward: 319.98849614639624 Explore P: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 392 Total reward: 289.6615079430957 Explore P: 0.0100\n",
      "Episode: 393 Total reward: 451.9655307494479 Explore P: 0.0100\n",
      "Episode: 394 Total reward: 219.2954776262613 Explore P: 0.0100\n",
      "Episode: 395 Total reward: 220.05996084708715 Explore P: 0.0100\n",
      "Episode: 396 Total reward: 494.57579663499774 Explore P: 0.0100\n",
      "Episode: 397 Total reward: 467.5493545128908 Explore P: 0.0100\n",
      "Episode: 398 Total reward: 189.73873441631562 Explore P: 0.0100\n",
      "Episode: 399 Total reward: 254.57157498026854 Explore P: 0.0100\n",
      "Episode: 400 Total reward: 172.83109683939756 Explore P: 0.0100\n",
      "Episode: 401 Total reward: 473.89112958203697 Explore P: 0.0100\n",
      "Episode: 402 Total reward: 205.65154143756448 Explore P: 0.0100\n",
      "Episode: 403 Total reward: 484.35854884082585 Explore P: 0.0100\n",
      "Episode: 404 Total reward: 470.3297979873997 Explore P: 0.0100\n",
      "Episode: 405 Total reward: 325.95396381491776 Explore P: 0.0100\n",
      "Episode: 406 Total reward: 409.5608266394435 Explore P: 0.0100\n",
      "Episode: 407 Total reward: 220.14905699807937 Explore P: 0.0100\n",
      "Episode: 408 Total reward: 493.21763104270104 Explore P: 0.0100\n",
      "Episode: 409 Total reward: 344.6221933989616 Explore P: 0.0100\n",
      "Episode: 410 Total reward: 476.3484591220534 Explore P: 0.0100\n",
      "Episode: 411 Total reward: 301.91220320880063 Explore P: 0.0100\n",
      "Episode: 412 Total reward: 477.41136566253317 Explore P: 0.0100\n",
      "Episode: 413 Total reward: 473.99433801849875 Explore P: 0.0100\n",
      "Episode: 414 Total reward: 480.4672005679487 Explore P: 0.0100\n",
      "Episode: 415 Total reward: 188.68105337839836 Explore P: 0.0100\n",
      "Episode: 416 Total reward: 491.92840562513766 Explore P: 0.0100\n",
      "Episode: 417 Total reward: 473.9977391504762 Explore P: 0.0100\n",
      "Episode: 418 Total reward: 473.41021822595553 Explore P: 0.0100\n",
      "Episode: 419 Total reward: 470.7989354924286 Explore P: 0.0100\n",
      "Episode: 420 Total reward: 485.61755024971995 Explore P: 0.0100\n",
      "Episode: 421 Total reward: 473.22326699567327 Explore P: 0.0100\n",
      "Episode: 422 Total reward: 487.7262070347322 Explore P: 0.0100\n",
      "Episode: 423 Total reward: 480.83694902526963 Explore P: 0.0100\n",
      "Episode: 424 Total reward: 251.37261836818388 Explore P: 0.0100\n",
      "Episode: 425 Total reward: 194.23717943531094 Explore P: 0.0100\n",
      "Episode: 426 Total reward: 342.94747912551827 Explore P: 0.0100\n",
      "Episode: 427 Total reward: 315.9225487819901 Explore P: 0.0100\n",
      "Episode: 428 Total reward: 377.05557446232575 Explore P: 0.0100\n",
      "Episode: 429 Total reward: 483.33968050210126 Explore P: 0.0100\n",
      "Episode: 430 Total reward: 489.17892098054796 Explore P: 0.0100\n",
      "Episode: 431 Total reward: 474.8997341035408 Explore P: 0.0100\n",
      "Episode: 432 Total reward: 197.38343975896254 Explore P: 0.0100\n",
      "Episode: 433 Total reward: 177.13071359231716 Explore P: 0.0100\n",
      "Episode: 434 Total reward: 483.83507536538553 Explore P: 0.0100\n",
      "Episode: 435 Total reward: 476.0083260903815 Explore P: 0.0100\n",
      "Episode: 436 Total reward: 482.03610177605566 Explore P: 0.0100\n",
      "Episode: 437 Total reward: 328.34003383413756 Explore P: 0.0100\n",
      "Episode: 438 Total reward: 489.4921180257829 Explore P: 0.0100\n",
      "Episode: 439 Total reward: 238.26171665700346 Explore P: 0.0100\n",
      "Episode: 440 Total reward: 189.37300803057192 Explore P: 0.0100\n",
      "Episode: 441 Total reward: 485.41383623163375 Explore P: 0.0100\n",
      "Episode: 442 Total reward: 486.2874640333846 Explore P: 0.0100\n",
      "Episode: 443 Total reward: 478.7751721887479 Explore P: 0.0100\n",
      "Episode: 444 Total reward: 181.82540724415352 Explore P: 0.0100\n",
      "Episode: 445 Total reward: 474.1631052128267 Explore P: 0.0100\n",
      "Episode: 446 Total reward: 482.42603363610607 Explore P: 0.0100\n",
      "Episode: 447 Total reward: 489.4209915680886 Explore P: 0.0100\n",
      "Episode: 448 Total reward: 471.60574648804203 Explore P: 0.0100\n",
      "Episode: 449 Total reward: 473.5396060597585 Explore P: 0.0100\n",
      "Episode: 450 Total reward: 472.9395912558262 Explore P: 0.0100\n",
      "Episode: 451 Total reward: 473.9454418689377 Explore P: 0.0100\n",
      "Episode: 452 Total reward: 475.4709341720691 Explore P: 0.0100\n",
      "Episode: 453 Total reward: 477.7935965188884 Explore P: 0.0100\n",
      "Episode: 454 Total reward: 475.1840640601562 Explore P: 0.0100\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment these next 2 lines to watch the training\n",
    "            env.render() \n",
    "            sleep(0.0005)\n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # reduce the reward if the cart is not centered\n",
    "            reward = max(0, reward * (1 - abs(next_state[0]/2.4)))\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        # if the agent gets 10 rewards bigger than 470 consecutively, stop the training\n",
    "        # 499 is never going to be reached because of the penalized reward\n",
    "        if len(rewards_list) > 10:\n",
    "            stop_training = False\n",
    "            for reward in rewards_list[-10:]:\n",
    "                if reward[1] < 470:\n",
    "                    break\n",
    "            else:\n",
    "                stop_training = True\n",
    "            if stop_training:\n",
    "                break\n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total Reward')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch a trained agent\n",
    "Note that the episode ends after 500 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_agent(n_episodes):\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        for episode in range(n_episodes):\n",
    "            state = env.reset()\n",
    "            r = 0\n",
    "            while True:\n",
    "                r += 1\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                env.render()\n",
    "                sleep(0.05)\n",
    "                # comment this if statement to see an endless episode\n",
    "                if done:\n",
    "                    env.close()\n",
    "                    print(f\"reward: {r}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n",
      "reward: 500\n",
      "reward: 500\n",
      "reward: 500\n"
     ]
    }
   ],
   "source": [
    "watch_agent(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
